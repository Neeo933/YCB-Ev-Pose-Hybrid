import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torch.cuda.amp import autocast, GradScaler
import numpy as np
import os
from tqdm import tqdm
import cv2
import matplotlib.pyplot as plt

# å¼•å…¥ä½ çš„æ¨¡å—
from a2dataset import GMGPoseDataset
from a3model import GMGPVNet
from a5loss import PVNetLoss

# ================= 1. å…¨å±€é…ç½® =================
CONFIG = {
    # è·¯å¾„è®¾ç½® (è¯·ç¡®ä¿è¿™äº›è·¯å¾„å­˜åœ¨)
    "processed_dir": "./processed_data",
    "dataset_root": "../ycb_ev_data/dataset/test_pbr", 
    
    # è®­ç»ƒè¶…å‚æ•°
    "batch_size": 16,          # æ˜¾å­˜ä¸å¤Ÿæ”¹å° (8 æˆ– 4)
    "num_workers": 6,          # CPU æ ¸å¿ƒæ•°
    "lr": 1e-4,                # åˆå§‹å­¦ä¹ ç‡
    "epochs": 50,              # è®­ç»ƒè½®æ•°
    
    # ç¡¬ä»¶ä¸ä¿å­˜
    "device": "cuda" if torch.cuda.is_available() else "cpu",
    "save_dir": "./checkpoints",
    "visualize_freq": 1        # æ¯å¤šå°‘ä¸ª Epoch ä¿å­˜ä¸€æ¬¡å¯è§†åŒ–å›¾ç‰‡
}


# ================= 2. å¯è§†åŒ–ç›‘æ§å‡½æ•° (å‡çº§ç‰ˆ) =================
def save_visualization(epoch, batch_data, pred_vec, pred_mask, save_path):
    """
    å‡çº§ç‰ˆå¯è§†åŒ–ï¼šå¢åŠ  Pred Mask å±•ç¤ºï¼Œè°ƒæ•´å¸ƒå±€ä¸º 2è¡Œ4åˆ—
    """
    # å– Batch ä¸­çš„ç¬¬ä¸€å¼ å›¾
    inputs = batch_data['input']
    depth = batch_data['depth']
    # æ³¨æ„ï¼šè¿™é‡Œçš„ gt_mask åº”è¯¥æ˜¯æˆ‘ä»¬ç”¨ depth ç®—å‡ºæ¥çš„é‚£ä¸ªï¼Œç¨ååœ¨ train é‡Œä¼ å…¥
    # è¿™é‡Œæˆ‘ä»¬å…ˆå– dataset é‡Œçš„åŸå§‹ mask åšå¯¹æ¯”
    gt_mask_orig = batch_data['mask']
    gt_vec = batch_data['target_field']
    
    # 1. è¿˜åŸ RGB
    rgb = inputs[0, :3].cpu().detach().numpy().transpose(1, 2, 0)
    rgb = (rgb * 255).astype(np.uint8)
    rgb = cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)
    
    # 2. è¿˜åŸ Depth
    d_vis = depth[0, 0].cpu().detach().numpy()
    
    # 3. Mask å¤„ç†
    # åŸå§‹æ–¹å½¢ Mask
    m_gt_box = gt_mask_orig[0, 0].cpu().detach().numpy()
    # é¢„æµ‹ Mask (Sigmoid -> 0~1)
    m_pred = torch.sigmoid(pred_mask[0, 0]).cpu().detach().numpy()
    
    # 4. Vector Field (å½’ä¸€åŒ–æ˜¾ç¤º X åˆ†é‡)
    def norm_v(v):
        v = v[0, 0].cpu().detach().numpy()
        return (v - v.min()) / (v.max() - v.min() + 1e-6)
    
    v_gt = norm_v(gt_vec)
    v_pred = norm_v(pred_vec)

    # 5. ç»˜å›¾ (2è¡Œ4åˆ—)
    fig, axs = plt.subplots(2, 4, figsize=(16, 8))
    
    # --- Row 1: è¾“å…¥ä¸ Mask ---
    axs[0,0].imshow(rgb)
    axs[0,0].set_title(f"Ep{epoch} Input RGB")
    
    axs[0,1].imshow(d_vis, cmap='plasma')
    axs[0,1].set_title("Input Depth")
    
    axs[0,2].imshow(m_gt_box, cmap='gray')
    axs[0,2].set_title("GT Mask (Box/Depth)") # çœ‹çœ‹æ˜¯ä¸æ˜¯å˜æˆäº†è½®å»“ï¼Ÿ
    
    axs[0,3].imshow(m_pred, cmap='gray')
    axs[0,3].set_title("Pred Mask Prob") # <--- è¿™é‡Œå°±æ˜¯ä½ è¦çœ‹çš„é¢„æµ‹Mask
    
    # --- Row 2: å‘é‡åœº ---
    axs[1,0].imshow(v_gt, cmap='jet')
    axs[1,0].set_title("GT Vector X")
    
    axs[1,1].imshow(v_pred, cmap='jet')
    axs[1,1].set_title("Pred Vector X")
    
    # ç•™ä¸¤ä¸ªç©ºä½æˆ–è€…ç”»ç‚¹åˆ«çš„
    axs[1,2].axis('off')
    axs[1,3].axis('off')
    
    plt.tight_layout()
    os.makedirs(save_path, exist_ok=True)
    plt.savefig(f"{save_path}/epoch_{epoch:03d}.png")
    plt.close()

# ================= 3. ä¸»è®­ç»ƒæµç¨‹ =================
def train():
    # åˆå§‹åŒ–ç›®å½•
    os.makedirs(CONFIG["save_dir"], exist_ok=True)
    vis_dir = os.path.join(CONFIG["save_dir"], "vis_logs1221")
    
    # --- A. æ•°æ®åŠ è½½ ---
    print(f"æ­£åœ¨åŠ è½½æ•°æ® (Root: {CONFIG['dataset_root']})...")
    dataset = GMGPoseDataset(
        processed_dir=CONFIG["processed_dir"], 
        dataset_root=CONFIG["dataset_root"],
        target_size=(128, 128),
        mode='train'
    )
    
    loader = DataLoader(
        dataset, 
        batch_size=CONFIG["batch_size"], 
        shuffle=True, 
        num_workers=CONFIG["num_workers"],
        pin_memory=True,
        drop_last=True
    )
    print(f"åŠ è½½å®Œæˆï¼Œå…± {len(dataset)} ä¸ªæ ·æœ¬ã€‚")

    # --- B. æ¨¡å‹æ„å»º ---
    print("æ­£åœ¨æ„å»º GMG-PVNet...")
    model = GMGPVNet(num_keypoints=9).to(CONFIG["device"])
    
    # --- C. ä¼˜åŒ–å™¨ä¸ Loss ---
    optimizer = optim.Adam(model.parameters(), lr=CONFIG["lr"])
    criterion = PVNetLoss().to(CONFIG["device"])
    scaler = GradScaler() # æ··åˆç²¾åº¦è®­ç»ƒ

    best_loss = float('inf')

    # --- D. è®­ç»ƒå¾ªç¯ ---
    print("ğŸš€ å¼€å§‹è®­ç»ƒ!")
    for epoch in range(1, CONFIG["epochs"] + 1):
        model.train()
        epoch_loss = 0.0
        vec_loss_sum = 0.0
        seg_loss_sum = 0.0
        
        pbar = tqdm(loader, desc=f"Epoch {epoch}/{CONFIG['epochs']}")
        
        for batch in pbar:
            # 1. æ•°æ®æ¬è¿åˆ° GPU
            inputs = batch['input'].to(CONFIG["device"])   # [B, 4, H, W]
            depth = batch['depth'].to(CONFIG["device"])    # [B, 1, H, W]
            gt_vec = batch['target_field'].to(CONFIG["device"])
            gt_mask = batch['mask'].to(CONFIG["device"])
            
            # 2. å‰å‘ä¼ æ’­ (æ··åˆç²¾åº¦)
            optimizer.zero_grad()
            with autocast():
                # æ³¨æ„ï¼šè¿™é‡Œè¿˜æ²¡æœ‰ç”¨ event_pointsï¼Œè®¾ä¸º None
                pred_vec, pred_mask = model(inputs, depth, event_points=None)
                
                # è®¡ç®— Loss
                loss, l_vec, l_seg = criterion(pred_vec, pred_mask, gt_vec, gt_mask)

                weighted_loss = l_seg + 10.0 * l_vec 

            
            # 3. åå‘ä¼ æ’­
            scaler.scale(weighted_loss).backward()
            scaler.step(optimizer)
            scaler.update()
            
            # 4. è®°å½•æ—¥å¿—
            epoch_loss += loss.item()
            vec_loss_sum += l_vec.item()
            seg_loss_sum += l_seg.item()
            
            pbar.set_postfix({
                "Total": f"{loss.item():.3f}",
                "Vec": f"{l_vec.item():.3f}",
                "Seg": f"{l_seg.item():.3f}"
            })

        # --- E. Epoch æ€»ç»“ ---
        avg_loss = epoch_loss / len(loader)
        avg_vec = vec_loss_sum / len(loader)
        avg_seg = seg_loss_sum / len(loader)
        
        print(f"Epoch {epoch} ç»“æŸ | Total: {avg_loss:.4f} (Vec: {avg_vec:.4f}, Seg: {avg_seg:.4f})")
        
        # ä¿å­˜æ¨¡å‹
        torch.save(model.state_dict(), f"{CONFIG['save_dir']}/last.pth")
        if avg_loss < best_loss:
            best_loss = avg_loss
            torch.save(model.state_dict(), f"{CONFIG['save_dir']}/best.pth")
            print("ğŸ† æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜!")

        # å¯è§†åŒ–

        if epoch % CONFIG["visualize_freq"] == 0:
            save_visualization(epoch, batch, pred_vec, pred_mask, vis_dir)

if __name__ == "__main__":
    train()