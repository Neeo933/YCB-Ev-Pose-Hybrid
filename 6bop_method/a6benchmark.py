import torch
import numpy as np
import cv2
import os
from tqdm import tqdm
from scipy.spatial import cKDTree
import glob
from scipy.spatial import cKDTree  

# å¼•å…¥ä½ çš„æ¨¡å—
from c2dataset import GMGPoseDataset
from d3model import GMGPVNet

# ================= é…ç½® =================
CONFIG = {
    "model_path": "./cloudcheckpoint1222v5/with_points/last.pth", 
    "processed_dir": "../dataset/processed_data",
    "dataset_root": "../dataset/test_pbr",
    "model_mesh_root": None, # å¦‚æœæœ‰ .ply æ–‡ä»¶å¡«è¿™é‡Œ
    
    "device": "cuda" if torch.cuda.is_available() else "cpu",
    "ref_size": 50.0, 
    "cam_K": np.array([
        [1066.778, 0.0, 312.9869],
        [0.0, 1067.487, 241.3109],
        [0.0, 0.0, 1.0]
    ]),
    "num_eval_samples": 500,
    "vis_interval": 50, # æ¯éš”å¤šå°‘å¸§ä¿å­˜ä¸€å¼ å¯è§†åŒ–å›¾
    "vis_dir": "./benchmark_vis" # å¯è§†åŒ–ä¿å­˜è·¯å¾„
}

class BenchmarkRunner:
    def __init__(self):
        self.device = CONFIG["device"]
        os.makedirs(CONFIG["vis_dir"], exist_ok=True)
        
        print(f"Loading Model: {CONFIG['model_path']}")
        self.model = GMGPVNet(num_keypoints=9).to(self.device)
        self.model.load_state_dict(torch.load(CONFIG["model_path"], map_location=self.device))
        self.model.eval()
        
        self.meshes = {} 
        
        # 3D å…³é”®ç‚¹å®šä¹‰ (å¿…é¡»ä¸ DataFactory ä¿æŒä¸€è‡´ï¼Œä¸­å¿ƒç‚¹åœ¨æœ€å)
        s = CONFIG["ref_size"]
        self.box_pts_3d = np.array([
            [s,s,s], [s,s,-s], [s,-s,s], [s,-s,-s],
            [-s,s,s], [-s,s,-s], [-s,-s,s], [-s,-s,-s],
            [0,0,0] # Center at index 8
        ], dtype=np.float32)

    def load_mesh_points(self, obj_id):
        """åŠ è½½ Mesh ç”¨äºè®¡ç®— ADD"""
        if obj_id in self.meshes: return self.meshes[obj_id]
        
        # é™çº§æ–¹æ¡ˆï¼šéšæœºé‡‡æ ·
        s = CONFIG["ref_size"]
        dummy_pts = np.random.uniform(-s, s, (500, 3)).astype(np.float32)
        self.meshes[obj_id] = dummy_pts
        return dummy_pts

    # def get_voting_kpts(self, pred_vec, pred_mask):
    #     """RANSAC / WLS æŠ•ç¥¨"""
    #     c, h, w = pred_vec.shape
    #     mask = torch.sigmoid(pred_mask[0]) > 0.9
    #     y_idxs, x_idxs = torch.where(mask)
        
    #     if len(x_idxs) < 10: return None # åƒç´ å¤ªå°‘ï¼Œè§†ä¸ºæ£€æµ‹å¤±è´¥

    #     coords = torch.stack([x_idxs, y_idxs], dim=1).float().cpu().numpy()
    #     vectors = pred_vec[:, mask].cpu().numpy().T 
        
    #     kpts_pred = []
    #     for k in range(9):
    #         vx = vectors[:, k*2]
    #         vy = vectors[:, k*2+1]
    #         A = np.stack([vy, -vx], axis=1)
    #         b = vy * coords[:, 0] - vx * coords[:, 1]
    #         res, _, _, _ = np.linalg.lstsq(A, b, rcond=None)
    #         kpts_pred.append(res)
            
    #     return np.array(kpts_pred)
    def get_voting_kpts(self, pred_vec, pred_mask):
        """
        RANSAC æŠ•ç¥¨ï¼šæŠ—å™ªèƒ½åŠ›æ›´å¼º
        """
        c, h, w = pred_vec.shape
        # æé«˜ Mask é˜ˆå€¼ï¼Œåªå–æœ€å¯ä¿¡çš„åƒç´ 
        mask = torch.sigmoid(pred_mask[0]) > 0.5
        y_idxs, x_idxs = torch.where(mask)
        
        # ç‚¹å¤ªå°‘ç›´æ¥æ”¾å¼ƒ
        if len(x_idxs) < 30: return None

        coords = torch.stack([x_idxs, y_idxs], dim=1).float().cpu().numpy() # [N, 2]
        vectors = pred_vec[:, mask].cpu().numpy().T # [N, 18]
        
        kpts_2d = []
        
        # å¯¹ 9 ä¸ªå…³é”®ç‚¹åˆ†åˆ«è®¡ç®—
        for k in range(9):
            vx = vectors[:, k*2]
            vy = vectors[:, k*2+1]
            
            # æ„é€  RANSAC éœ€è¦çš„æ•°æ®å½¢å¼
            # è¿™é‡Œçš„æ€è·¯æ˜¯ï¼šæˆ‘ä»¬åœ¨ N ä¸ªåƒç´ ä¸­ï¼Œéšæœºé€‰ 2 ä¸ªç‚¹ï¼Œç®—å‡ºå®ƒä»¬çš„äº¤ç‚¹
            # é‡å¤å¤šæ¬¡ï¼Œçœ‹å“ªä¸ªäº¤ç‚¹è¢«æ”¯æŒå¾—æœ€å¤š
            
            # ä¸ºäº†ç®€å•é«˜æ•ˆï¼Œæˆ‘ä»¬ä½¿ç”¨ OpenCV çš„ RANSAC æ€æƒ³
            # ä½† OpenCV æ²¡æœ‰ç›´æ¥é’ˆå¯¹â€œå‘é‡åœºäº¤ç‚¹â€çš„ RANSAC å‡½æ•°
            # è¿™é‡Œæä¾›ä¸€ä¸ªç®€åŒ–çš„â€œåŠ æƒä¸­ä½æ•°â€ç­–ç•¥ï¼Œæ¯”æœ€å°äºŒä¹˜é²æ£’å¾—å¤š
            
            A = np.stack([vy, -vx], axis=1)
            b = vy * coords[:, 0] - vx * coords[:, 1]
            
            # 1. åˆæ­¥è§£ (æœ€å°äºŒä¹˜)
            initial_kp, _, _, _ = np.linalg.lstsq(A, b, rcond=None)
            
            # 2. è®¡ç®—æ¯ä¸ªåƒç´ å¯¹è¿™ä¸ªè§£çš„â€œæ»¡æ„åº¦â€ (Residual Error)
            # ç†æƒ³å‘é‡ vs å®é™…å‘é‡ çš„ä½™å¼¦ç›¸ä¼¼åº¦
            vec_to_kp = initial_kp - coords
            dist = np.linalg.norm(vec_to_kp, axis=1) + 1e-6
            vec_to_kp_norm = vec_to_kp / dist[:, None]
            
            dot_prod = vec_to_kp_norm[:, 0] * vx + vec_to_kp_norm[:, 1] * vy
            
            # 3. å‰”é™¤ç¦»ç¾¤ç‚¹ (Inlier Selection)
            # åªæœ‰æ–¹å‘åå·®å°äºä¸€å®šè§’åº¦ (æ¯”å¦‚ cos > 0.9) çš„ç‚¹æ‰æ˜¯å¥½ç‚¹
            inliers = dot_prod > 0.9
            
            if np.sum(inliers) > 10:
                # 4. ç”¨å¥½ç‚¹å†ç®—ä¸€æ¬¡ (Refinement)
                A_in = A[inliers]
                b_in = b[inliers]
                final_kp, _, _, _ = np.linalg.lstsq(A_in, b_in, rcond=None)
                kpts_2d.append(final_kp)
            else:
                # å¦‚æœå¥½ç‚¹å¤ªå°‘ï¼Œè¯´æ˜é¢„æµ‹å¾ˆçƒ‚ï¼Œåªèƒ½ç”¨åˆå§‹è§£å‡‘åˆ
                kpts_2d.append(initial_kp)
            
        return np.array(kpts_2d)
    # def compute_add_metric(self, R_pred, t_pred, R_gt, t_gt, obj_id):
    #     pts = self.load_mesh_points(obj_id.item())
    #     pts_pred = (np.dot(pts, R_pred.T) + t_pred.T)
    #     pts_gt = (np.dot(pts, R_gt.T) + t_gt.T)
    #     return np.mean(np.linalg.norm(pts_pred - pts_gt, axis=1))

    def compute_add_metric(self, R_pred, t_pred, R_gt, t_gt, obj_id):
        """
        è®¡ç®—å§¿æ€è¯¯å·®ï¼š
        - éå¯¹ç§°ç‰©ä½“ï¼šä½¿ç”¨ ADD (Average Distance of Model Points)
        - å¯¹ç§°ç‰©ä½“ï¼šä½¿ç”¨ ADD-S (Average Distance of Model Points with Symmetry)
        """
        pts = self.load_mesh_points(obj_id.item())
        
        # 1. å°†æ¨¡å‹ç‚¹äº‘å˜æ¢åˆ°ç›¸æœºåæ ‡ç³»
        pts_pred = (np.dot(pts, R_pred.T) + t_pred.T)
        pts_gt = (np.dot(pts, R_gt.T) + t_gt.T)
        
        # 2. å®šä¹‰å¯¹ç§°ç‰©ä½“çš„ ID åˆ—è¡¨ (YCB-Video æ•°æ®é›†æ ‡å‡†)
        # ID è¯´æ˜: 
        # 13: bowl (ç¢—)
        # 16: abrasive sponge (æµ·ç»µæ“¦ - ä¹Ÿæ˜¯å‡ ä½•å¯¹ç§°çš„)
        # 19: pitcher base (æ°´å£¶åº•)
        # 20: gelatin box (æœå†»ç›’ - çº¹ç†å¯¹ç§°)
        # 21: potted meat (ç½å¤´)
        # 24: extra_large_clamp (å¤§å¤¹å­ - ä¹Ÿæ˜¯å‡ ä½•å¯¹ç§°)
        # è¯·æ ¹æ®ä½ çš„ dataset/test_pbr é‡Œçš„å®é™… obj_id ç¡®è®¤è¿™äº›æ•°å­—
        symmetric_ids = [13, 16, 19, 20, 21, 24] 
        
        # 3. æ ¹æ®ç‰©ä½“ç±»å‹é€‰æ‹©ç®—æ³•
        if int(obj_id) in symmetric_ids:
            # === ADD-S (é’ˆå¯¹å¯¹ç§°ç‰©ä½“) ===
            # é€»è¾‘ï¼šå¯¹äºé¢„æµ‹ç‚¹äº‘ä¸­çš„æ¯ä¸€ä¸ªç‚¹ï¼Œåœ¨çœŸå€¼ç‚¹äº‘ä¸­æ‰¾ä¸€ä¸ªç¦»å®ƒæœ€è¿‘çš„ç‚¹ç®—è·ç¦»
            # è¿™æ ·å³ä½¿æ—‹è½¬å·®äº† 180 åº¦ï¼ˆå¯¹äºå¯¹ç§°ç‰©ä½“å¤–è§‚ä¸€æ ·ï¼‰ï¼Œè¯¯å·®ä¹Ÿä¼šå¾ˆå°
            kdtree = cKDTree(pts_gt)
            distances, _ = kdtree.query(pts_pred) # è¿”å›æ¯ä¸ªç‚¹çš„æœ€è¿‘é‚»è·ç¦»
            mean_dist = np.mean(distances)
        else:
            # === ADD (é’ˆå¯¹éå¯¹ç§°ç‰©ä½“) ===
            # é€»è¾‘ï¼šç‚¹å¯¹ç‚¹ä¸¥æ ¼å¯¹åº”è®¡ç®—è·ç¦»
            mean_dist = np.mean(np.linalg.norm(pts_pred - pts_gt, axis=1))
            
        return mean_dist

    def draw_visuals(self, img_path, kpts_pred,kpts_gt, rvec, tvec, save_name):
        """ç»˜åˆ¶ 2D å…³é”®ç‚¹å’Œ 3D åŒ…å›´ç›’"""
        img = cv2.imread(img_path)
        if img is None: return

        # 1. ç”» 2D é¢„æµ‹ç‚¹ (é»„è‰²)
        for kp in kpts_pred:
            cv2.circle(img, (int(kp[0]), int(kp[1])), 3, (0, 255, 255), -1)

        # 2. [æ–°å¢] ç”» 2D çœŸå€¼ç‚¹ (çº¢è‰² - GT)
    # è¿™èƒ½è®©ä½ ä¸€çœ¼çœ‹å‡ºæ˜¯ç½‘ç»œé¢„æµ‹æ­ªäº†ï¼Œè¿˜æ˜¯åæ ‡ç³»æœ¬èº«å°±æ­ªäº†
        for kp in kpts_gt:
            cv2.circle(img, (int(kp[0]), int(kp[1])), 2, (0, 0, 255), -1)
            
        # 2. ç”» 3D æŠ•å½±æ¡† (ç»¿è‰²)
        # åªç”¨å‰8ä¸ªè§’ç‚¹ç”»æ¡†
        img_pts, _ = cv2.projectPoints(self.box_pts_3d[:8], rvec, tvec, CONFIG["cam_K"], None)
        img_pts = img_pts.squeeze().astype(int)
        
        # å®šä¹‰ç«‹æ–¹ä½“çš„ 12 æ¡æ£± (åŸºäº 0-7 çš„ç´¢å¼•)
        edges = [
            (0,1), (0,2), (0,4), 
            (1,3), (1,5), 
            (2,3), (2,6), 
            (3,7), 
            (4,5), (4,6), 
            (5,7), 
            (6,7)
        ]
        
        # ç»˜åˆ¶çº¿æ¡†
        for s, e in edges:
            # å¢åŠ è¾¹ç•Œæ£€æŸ¥é˜²æ­¢ç”»å‡ºå›¾å¤–æŠ¥é”™
            if 0 <= s < len(img_pts) and 0 <= e < len(img_pts):
                cv2.line(img, tuple(img_pts[s]), tuple(img_pts[e]), (0, 255, 0), 2)

        cv2.imwrite(save_name, img)

    def run(self):
        dataset = GMGPoseDataset(
            processed_dir=CONFIG["processed_dir"], 
            dataset_root=CONFIG["dataset_root"],
            mode='train' 
        )
        
        total_samples = len(dataset)
        if CONFIG["num_eval_samples"]:
            indices = np.random.choice(total_samples, CONFIG["num_eval_samples"], replace=False)
        else:
            indices = range(total_samples)
            
        print(f"Start Benchmarking on {len(indices)} samples...")
        
        # === ç»Ÿè®¡è®¡æ•°å™¨ ===
        stats = {
            "total": len(indices),
            "success_10": 0,    # ADD < 0.1d
            "fail_det": 0,      # Mask åƒç´ ä¸è¶³ (Detection Failed)
            "fail_pnp": 0,      # PnP è§£ç®—å¤±è´¥
            "fail_large_err": 0 # è§£ç®—æˆåŠŸä½†è¯¯å·®è¿‡å¤§
        }
        
        add_errors = []
        diameter = 150.0 # mm
        
        for i, idx in enumerate(tqdm(indices)):
            sample = dataset[idx]
            
            inputs = sample['input'].unsqueeze(0).to(self.device)
            depth = sample['depth'].unsqueeze(0).to(self.device)
            event_points = sample['event_points'].unsqueeze(0).to(self.device) if 'event_points' in sample else None
            if 'template' in sample:
                template = sample['template'].unsqueeze(0).to(self.device)
            else:
                # å®¹é”™ï¼šå¦‚æœæ—§ç‰ˆ Dataset æ²¡è¿”å› templateï¼Œé€ ä¸€ä¸ªå…¨é»‘çš„
                # ä½†è¿™ä¼šä¸¥é‡å½±å“ç²¾åº¦ï¼Œå»ºè®®åŠ¡å¿…æ›´æ–° Dataset
                template = torch.zeros_like(inputs[:, :3, :, :])

            if 'event_points' in sample:
                event_points = sample['event_points'].unsqueeze(0).to(self.device)
            else:
                event_points = None

            # 1. æ¨ç†
            with torch.no_grad():
                # [ä¿®æ”¹] ä¼ å…¥ template
                pred_vec, pred_mask = self.model(inputs, depth, template, event_points)
     
            # 2. æŠ•ç¥¨
            kpts_crop = self.get_voting_kpts(pred_vec[0], pred_mask[0])
            
            # [ç»Ÿè®¡] æ£€æµ‹å¤±è´¥
            if kpts_crop is None:
                stats["fail_det"] += 1
                add_errors.append(1000.0)
                continue
                
            # 3. åæ ‡è¿˜åŸ
            # scale = sample['scale'].numpy()
            # offset = sample['offset'].numpy()
            
            # kpts_global = kpts_crop.copy()
            # kpts_global[:, 0] = kpts_crop[:, 0] / scale[0] + offset[0]
            # kpts_global[:, 1] = kpts_crop[:, 1] / scale[1] + offset[1]

            # # === [æ–°å¢] åæ ‡è¿˜åŸ (GT) ===
            # # ä» Dataset æ‹¿åŸå§‹çš„ local gt
            # kpts_gt_local = sample['kpts_local'].numpy()
            # kpts_gt_global = kpts_gt_local.copy()
            # kpts_gt_global[:, 0] = kpts_gt_local[:, 0] / scale[0] + offset[0]
            # kpts_gt_global[:, 1] = kpts_gt_local[:, 1] / scale[1] + offset[1]
            # # ===========================

            # 3. åæ ‡è¿˜åŸ
            # ç›´æ¥ä¿¡ä»» Dataset ä¼ å‡ºæ¥çš„ scale å’Œ offsetï¼Œå› ä¸ºå®ƒä»¬æ˜¯è®­ç»ƒæ—¶â€œæ¡ˆå‘ç°åœºâ€çš„çœŸå®å‚æ•°
            scale = sample['scale'].numpy()   
            offset = sample['offset'].numpy() 
            
            kpts_global = kpts_crop.copy()
            kpts_global[:, 0] = kpts_crop[:, 0] / scale[0] + offset[0]
            kpts_global[:, 1] = kpts_crop[:, 1] / scale[1] + offset[1]
            
            # åŒç†è¿˜åŸ GT (ç”¨äºç”»çº¢ç‚¹éªŒè¯)
            kpts_gt_local = sample['kpts_local'].numpy()
            kpts_gt_global = kpts_gt_local.copy()
            kpts_gt_global[:, 0] = kpts_gt_local[:, 0] / scale[0] + offset[0]
            kpts_gt_global[:, 1] = kpts_gt_local[:, 1] / scale[1] + offset[1]

            
            # 4. PnP è§£ç®—
            ret_pred, rvec_pred, tvec_pred = cv2.solvePnP(
                self.box_pts_3d, kpts_global, CONFIG["cam_K"], None, flags=cv2.SOLVEPNP_EPNP
            )


            # ## éªŒè¯y
            #  # 3. åæ ‡è¿˜åŸ (GT)
            # # æˆ‘ä»¬å…ˆä¸çœ‹é¢„æµ‹çš„ kpts_globalï¼Œæˆ‘ä»¬ç›´æ¥ç”¨ GT çš„ç‚¹ï¼
            # kpts_gt_local = sample['kpts_local'].numpy()
            # scale = sample['scale'].numpy()
            # offset = sample['offset'].numpy()
            
            # kpts_gt_global = kpts_gt_local.copy()
            # kpts_gt_global[:, 0] = kpts_gt_local[:, 0] / scale[0] + offset[0]
            # kpts_gt_global[:, 1] = kpts_gt_local[:, 1] / scale[1] + offset[1]

            # # 4. PnP è§£ç®— (æ³¨æ„ï¼šè¿™é‡Œä¼ å…¥ kpts_gt_global !!!)
            # # æˆ‘ä»¬çœ‹çœ‹ç”¨å®Œç¾çš„ç‚¹ï¼Œèƒ½ä¸èƒ½ç®—å‡ºå®Œç¾çš„ Pose
            # ret_pred, rvec_pred, tvec_pred = cv2.solvePnP(
            #     self.box_pts_3d, 
            #     kpts_gt_global,  # <--- æ¢æˆ GT !
            #     CONFIG["cam_K"], 
            #     None, 
            #     flags=cv2.SOLVEPNP_EPNP
            # )
            
            # === [æ–°å¢] è·ç¦»ä¿æŠ¤æœºåˆ¶ ===
            # å¦‚æœç®—å‡ºæ¥çš„è·ç¦»å¤§äº 3ç±³ (YCBåœºæ™¯é€šå¸¸åœ¨1ç±³å·¦å³)ï¼Œè¯´æ˜ç‚¹ç¼©æˆä¸€å›¢äº†
            if tvec_pred[2] > 3000.0: 
                # å¼ºåˆ¶ä¿®æ­£ Z è½´åˆ° 1ç±³ (å‡è®¾)
                # è¿™æ˜¯ä¸€ç§ heuristicï¼Œè™½ç„¶ R è¿˜æ˜¯é”™çš„ï¼Œä½†è‡³å°‘ t ä¸ä¼šç¦»è°±
                scale_factor = 1000.0 / tvec_pred[2]
                tvec_pred = tvec_pred * scale_factor
                # æˆ–è€…æ ‡è®°ä¸ºå¤±è´¥
                # stats["fail_large_err"] += 1
            
            # [ç»Ÿè®¡] PnP å¤±è´¥
            if not ret_pred:
                stats["fail_pnp"] += 1
                add_errors.append(1000.0)
                continue
            
            # 5. ç®—åˆ†
            R_pred, _ = cv2.Rodrigues(rvec_pred)
            pose_gt = sample['pose_gt'].numpy()
            R_gt = pose_gt[:3, :3]
            t_gt = pose_gt[:3, 3]


            # ... (åœ¨ solvePnP ä¹‹å) ...
            
            # === [æ–°å¢] Debug è¯Šæ–­æ¨¡å— (åªæ‰“å°å‰å‡ ä¸ªæ ·æœ¬) ===
            if i < 3: 
                print(f"\n--- Debug Sample {idx} ---")
                
                # 1. æ£€æŸ¥ GT å’Œ Pred çš„å¹³ç§»å‘é‡ (t)
                # å¦‚æœ GT æ˜¯ ~1000ï¼ŒPred æ˜¯ ~13000ï¼Œè¯´æ˜ç¡®å®æ˜¯â€œç¼©æˆä¸€å›¢â€å¯¼è‡´æ¨å¾—å¤ªè¿œ
                print(f"GT  tvec (mm): {t_gt.flatten()}")
                print(f"Pred tvec (mm): {tvec_pred.flatten()}")
                
                # 2. æ£€æŸ¥ 2D å…³é”®ç‚¹çš„åˆ†å¸ƒèŒƒå›´ (Spread)
                # è®¡ç®— 2D ç‚¹çš„æ ‡å‡†å·®ï¼Œçœ‹æ˜¯ä¸æ˜¯ç¼©æˆä¸€å›¢
                spread_x = np.std(kpts_global[:, 0])
                spread_y = np.std(kpts_global[:, 1])
                print(f"Pred 2D Spread: X_std={spread_x:.2f}, Y_std={spread_y:.2f}")
                
                # å¦‚æœ std å¾ˆå° (æ¯”å¦‚ < 5.0)ï¼Œè¯´æ˜æ‰€æœ‰ç‚¹éƒ½æŒ¤åœ¨ä¸€èµ· -> æ¨¡å¼åå¡Œ
                if spread_x < 5.0 and spread_y < 5.0:
                    print("âš ï¸ è­¦å‘Šï¼šé¢„æµ‹å…³é”®ç‚¹é‡åˆï¼æ¨¡å‹å‘ç”Ÿäº†æ¨¡å¼åå¡Œ (Mode Collapse)ã€‚")
                else:
                    print("âœ… 2D å…³é”®ç‚¹åˆ†å¸ƒæ­£å¸¸ã€‚")

                # 3. æ£€æŸ¥ 3D æ¡†å°ºå¯¸ (Ref Size)
                # ç¡®ä¿ benchmark é‡Œçš„ ref_size å’Œè®­ç»ƒæ—¶ä¸€è‡´
                print(f"Ref Size used: {CONFIG['ref_size']}")
            # ===============================================

            # 6. ç®—åˆ†
            error = self.compute_add_metric(R_pred, tvec_pred.reshape(3), R_gt, t_gt, sample['obj_id'])
            add_errors.append(error)
            
            if error < 0.1 * diameter:
                stats["success_10"] += 1
            else:
                stats["fail_large_err"] += 1

            # 6. å¯è§†åŒ– (æ¯éš” N å¸§ä¿å­˜ä¸€å¼ )
            if i % CONFIG["vis_interval"] == 0:
                save_name = os.path.join(CONFIG["vis_dir"], f"eval_{i}_err{error:.1f}.jpg")
                self.draw_visuals(sample['rgb_path'], kpts_global, kpts_gt_global, rvec_pred, tvec_pred, save_name)

        # 7. æ‰“å°æœ€ç»ˆæŠ¥å‘Š
        accuracy = stats["success_10"] / stats["total"] * 100
        mean_error = np.mean(add_errors)
        
        print("\n" + "="*40)
        print(f"Model: {CONFIG['model_path']}")
        print(f"Total Samples: {stats['total']}")
        print("-" * 20)
        print(f"âœ… Accuracy (<10% d): {accuracy:.2f}%")
        print(f"ğŸ“ Mean ADD Error:    {mean_error:.2f} mm")
        print("-" * 20)
        print("Failure Analysis:")
        print(f"âŒ Detection Failed:  {stats['fail_det']} ({stats['fail_det']/stats['total']:.1%}) -> Mask too small/empty")
        print(f"âŒ PnP Failed:        {stats['fail_pnp']} ({stats['fail_pnp']/stats['total']:.1%}) -> Numerical instability")
        print(f"âŒ Large Error:       {stats['fail_large_err']} ({stats['fail_large_err']/stats['total']:.1%}) -> Pose inaccurate")
        print("="*40)
        print(f"Visualizations saved to: {CONFIG['vis_dir']}")

if __name__ == "__main__":
    bencher = BenchmarkRunner()
    bencher.run()