import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torch.amp import autocast, GradScaler # æ–°ç‰ˆPyTorchå»ºè®®å†™æ³•ï¼Œæ—§ç‰ˆç”¨ torch.cuda.amp ä¹Ÿå¯ä»¥
import numpy as np
import os
from tqdm import tqdm
import cv2
import json  # [æ–°å¢] ç”¨äºä¿å­˜æ•°æ®
import matplotlib.pyplot as plt

# å¼•å…¥ä½ çš„æ¨¡å—
from f2dataset import GMGPoseDataset
from d3model import GMGPVNet
from a5loss import PVNetLoss

## åªè®­ç»ƒä¸€ç§ç‰©ä½“
# ================= 1. å…¨å±€é…ç½® =================
CONFIG = {

    # --- å®éªŒå¼€å…³ (ä¿®æ”¹è¿™é‡Œæ¥åˆ‡æ¢å®éªŒ) ---
    "exp_name": "all_objects_v1",   # å®éªŒå: 'no_points' æˆ– 'with_points'
    "use_event_points": True,    # å¼€å…³: False (ä¸åŠ ç‚¹äº‘) / True (åŠ ç‚¹äº‘)
    # -----------------------------------
    "target_obj_id": None,
    
    "processed_dir": "../dataset/processed_data",
    "dataset_root": "../dataset/test_pbr", 
    "batch_size": 32,
    "num_workers": 6,
    "lr": 1e-4,
    "epochs": 100,
    "device": "cuda" if torch.cuda.is_available() else "cpu",
    "base_save_dir": "./cloudcheckpoint1223",
    "visualize_freq": 1 
}

# åŠ¨æ€ç”Ÿæˆä¿å­˜è·¯å¾„ï¼Œé˜²æ­¢è¦†ç›–
SAVE_DIR = os.path.join(CONFIG["base_save_dir"], CONFIG["exp_name"])

# ================= 2. è¾…åŠ©å·¥å…·ï¼šç»˜åˆ¶ Loss æ›²çº¿ =================
def plot_loss_curve(history, save_path):
    """
    ç»˜åˆ¶è®­ç»ƒè¿‡ç¨‹ä¸­çš„ Loss å˜åŒ–æ›²çº¿
    history: {'total': [], 'vec': [], 'seg': []}
    """
    epochs = range(1, len(history['total']) + 1)
    
    plt.figure(figsize=(12, 5))
    
    # å­å›¾1: Total Loss (åŠ æƒåçš„)
    plt.subplot(1, 2, 1)
    plt.plot(epochs, history['total'], 'b-', label='Weighted Total Loss')
    plt.title('Total Loss Curve')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.grid(True)
    plt.legend()
    
    # å­å›¾2: åˆ†é¡¹ Loss (åŸå§‹å€¼)
    plt.subplot(1, 2, 2)
    plt.plot(epochs, history['vec'], 'r-', label='Vector Loss (Raw)')
    plt.plot(epochs, history['seg'], 'g-', label='Seg Loss (Raw)')
    plt.title('Component Loss Curve')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.grid(True)
    plt.legend()
    
    plt.tight_layout()
    plt.savefig(save_path)
    plt.close()


def save_loss_json(history, save_path):
    """[æ–°å¢] ä¿å­˜ Loss æ•°æ®åˆ° JSON æ–‡ä»¶ï¼Œæ–¹ä¾¿åç»­å¯¹æ¯”"""
    with open(save_path, 'w') as f:
        json.dump(history, f, indent=4)

# ================= 3. å¯è§†åŒ–ç›‘æ§å‡½æ•° =================
def save_visualization(epoch, batch_data, pred_vec, pred_mask, save_path):
    inputs = batch_data['input']
    depth = batch_data['depth']
    gt_mask = batch_data['mask']
    gt_vec = batch_data['target_field']
    
    # 1. è¿˜åŸ RGB
    rgb = inputs[0, :3].cpu().detach().numpy().transpose(1, 2, 0)
    rgb = (rgb * 255).astype(np.uint8)
    rgb = cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)
    
    # 2. è¿˜åŸ Depth
    d_vis = depth[0, 0].cpu().detach().numpy()
    
    # 3. Mask å¤„ç†
    m_gt = gt_mask[0, 0].cpu().detach().numpy()
    m_pred = torch.sigmoid(pred_mask[0, 0]).cpu().detach().numpy()
    
    # 4. Vector Field (X channel)
    def norm_v(v):
        v = v[0, 0].cpu().detach().numpy()
        return (v - v.min()) / (v.max() - v.min() + 1e-6)
    
    v_gt = norm_v(gt_vec)
    v_pred = norm_v(pred_vec)

    # 5. ç»˜å›¾
    fig, axs = plt.subplots(2, 4, figsize=(16, 8))
    
    axs[0,0].imshow(rgb)
    axs[0,0].set_title(f"Ep{epoch} Input RGB")
    
    axs[0,1].imshow(d_vis, cmap='plasma')
    axs[0,1].set_title("Input Depth")
    
    axs[0,2].imshow(m_gt, cmap='gray')
    axs[0,2].set_title("GT Mask") 
    
    axs[0,3].imshow(m_pred, cmap='gray')
    axs[0,3].set_title("Pred Mask Prob")
    
    axs[1,0].imshow(v_gt, cmap='jet')
    axs[1,0].set_title("GT Vector X")
    
    axs[1,1].imshow(v_pred, cmap='jet')
    axs[1,1].set_title("Pred Vector X")
    
    axs[1,2].axis('off'); axs[1,3].axis('off')
    
    plt.tight_layout()
    os.makedirs(save_path, exist_ok=True)
    plt.savefig(f"{save_path}/epoch_{epoch:03d}.png")
    plt.close()

# ================= 3. ä¸»è®­ç»ƒæµç¨‹ =================
def train():
    # åˆå§‹åŒ–å½“å‰å®éªŒçš„ç›®å½•
    os.makedirs(SAVE_DIR, exist_ok=True)
    vis_dir = os.path.join(SAVE_DIR, "vis_logs")
    
    print(f"ğŸš€ Experiment: {CONFIG['exp_name']}")
    print(f"ğŸ“‚ Saving to: {SAVE_DIR}")
    print(f"â˜ï¸ Use Point Cloud: {CONFIG['use_event_points']}")

    # åŠ è½½æ•°æ®
    dataset = GMGPoseDataset(
        processed_dir=CONFIG["processed_dir"], 
        dataset_root=CONFIG["dataset_root"],
        target_size=(128, 128),
        mode='train',
        target_obj_id=CONFIG["target_obj_id"] # <--- ä¼ å…¥è¿™é‡Œ

    )
    
    loader = DataLoader(dataset, batch_size=CONFIG["batch_size"], 
                        shuffle=True, num_workers=CONFIG["num_workers"],
                        pin_memory=True, drop_last=True)
    
    model = GMGPVNet(num_keypoints=9).to(CONFIG["device"])
    optimizer = optim.Adam(model.parameters(), lr=CONFIG["lr"])
    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[20, 40], gamma=0.1)

    criterion = PVNetLoss().to(CONFIG["device"])
    scaler = GradScaler()

    best_loss = float('inf')
    loss_history = {'total': [], 'vec': [], 'seg': []}

    for epoch in range(1, CONFIG["epochs"] + 1):
        model.train()
        meter_total = 0.0
        meter_vec = 0.0
        meter_seg = 0.0
        
        pbar = tqdm(loader, desc=f"Epoch {epoch}/{CONFIG['epochs']}")
        
        for batch in pbar:
            inputs = batch['input'].to(CONFIG["device"])   
            depth = batch['depth'].to(CONFIG["device"])    
            gt_vec = batch['target_field'].to(CONFIG["device"])
            gt_mask = batch['mask'].to(CONFIG["device"])
            # [æ–°å¢] è·å– Template
            template = batch['template'].to(CONFIG["device"])
            # [æ ¸å¿ƒé€»è¾‘] æ ¹æ®é…ç½®å†³å®šæ˜¯å¦ä¼ ç‚¹äº‘
            if CONFIG["use_event_points"]:
                event_points = batch['event_points'].to(CONFIG["device"])
            else:
                event_points = None # ä¼  Noneï¼Œæ¨¡å‹å†…éƒ¨å°±ä¼šè·³è¿‡ PointNet åˆ†æ”¯
            
            optimizer.zero_grad()
            with autocast(device_type='cuda'):
                # ä¼ å…¥ event_points (å¯èƒ½æ˜¯ Tensor ä¹Ÿå¯èƒ½æ˜¯ None)
                pred_vec, pred_mask = model(inputs, depth,template,event_points=event_points)
                
                _, l_vec, l_seg = criterion(pred_vec, pred_mask, gt_vec, gt_mask)
                # weighted_loss = l_seg + 50.0 * l_vec 
            # === [æ ¸å¿ƒä¿®æ”¹] åŠ¨æ€æƒé‡ç­–ç•¥ ===
            # é˜¶æ®µ 1 (Epoch 1-5): ä¸“æ³¨å­¦ä¹  Maskï¼Œå‘é‡åœºæƒé‡å¾ˆä½æˆ–ä¸º0
            # é˜¶æ®µ 2 (Epoch 6-50): Mask ç¨³å®šäº†ï¼Œå¤§åŠ›è®­ç»ƒå‘é‡åœº
            
            if epoch <= 10:
                w_seg = 1.0
                w_vec = 0.0  # æˆ–è€… 1.0ï¼Œå…ˆåˆ«ç»™å¤ªå¤§å‹åŠ›
            else:
                w_seg = 1.0
                # Mask å·²ç»å­¦ä¼šäº†ï¼Œç°åœ¨å¼€å§‹æš´åŠ›æ‹‰æ‰¯å‘é‡åœº
                # ä¹‹å‰ 10.0 ä¸å¤Ÿï¼Œç°åœ¨å¯ä»¥è¯• 20.0 æˆ– 50.0 (100å¯èƒ½è¿˜æ˜¯å¤ªæ¿€è¿›ï¼Œå»ºè®®å…ˆè¯• 20)
                w_vec = 10.0 
            
            weighted_loss = w_seg * l_seg + w_vec * l_vec 
            # ============================

            scaler.scale(weighted_loss).backward()
            scaler.step(optimizer)
            scaler.update()
            
            meter_total += weighted_loss.item()
            meter_vec += l_vec.item()
            meter_seg += l_seg.item()
            
            pbar.set_postfix({"Loss": f"{weighted_loss.item():.3f}"})
            scheduler.step()


        # --- Epoch ç»“æŸ ---
        avg_total = meter_total / len(loader)
        avg_vec = meter_vec / len(loader)
        avg_seg = meter_seg / len(loader)
        
        # è®°å½•æ•°æ®
        loss_history['total'].append(avg_total)
        loss_history['vec'].append(avg_vec)
        loss_history['seg'].append(avg_seg)
        
        # ä¿å­˜æ—¥å¿— (æ¯æ¬¡éƒ½è¦†ç›–æ›´æ–°ï¼Œé˜²æ­¢ä¸­æ–­ä¸¢å¤±)
        save_loss_json(loss_history, f"{SAVE_DIR}/loss_log.json")
        plot_loss_curve(loss_history, f"{SAVE_DIR}/loss_curve.png")
        
        print(f"Ep {epoch} | Total: {avg_total:.4f} (Vec: {avg_vec:.4f})")
        
        # ä¿å­˜æ¨¡å‹
        torch.save(model.state_dict(), f"{SAVE_DIR}/last.pth")
        if avg_total < best_loss:
            best_loss = avg_total
            torch.save(model.state_dict(), f"{SAVE_DIR}/best.pth")

        if epoch % CONFIG["visualize_freq"] == 0:
            save_visualization(epoch, batch, pred_vec, pred_mask, vis_dir)

if __name__ == "__main__":
    train()