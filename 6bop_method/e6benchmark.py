import torch
import numpy as np
import cv2
import os
from tqdm import tqdm
from scipy.spatial import cKDTree
import glob
from scipy.spatial import cKDTree  

# å¼•å…¥ä½ çš„æ¨¡å—
from f2dataset import GMGPoseDataset
from d3model import GMGPVNet

# ================= é…ç½® =================
CONFIG = {
    "model_path": "./cloudcheckpoint1222v5/with_points_single_obj13/last.pth", 
    "processed_dir": "../dataset/processed_data",
    "dataset_root": "../dataset/test_pbr",
    "model_mesh_root": None, # å¦‚æœæœ‰ .ply æ–‡ä»¶å¡«è¿™é‡Œ
    "target_obj_id": None, # å¿…é¡»å’Œè®­ç»ƒæ—¶ä¸€è‡´

    
    "device": "cuda" if torch.cuda.is_available() else "cpu",
    "ref_size": 70.0, 
    "cam_K": np.array([
        [1066.778, 0.0, 312.9869],
        [0.0, 1067.487, 241.3109],
        [0.0, 0.0, 1.0]
    ]),
    "num_eval_samples": 2000,
    "vis_interval": 50, # æ¯éš”å¤šå°‘å¸§ä¿å­˜ä¸€å¼ å¯è§†åŒ–å›¾
    "vis_dir": "./benchmark_vis/1223" # å¯è§†åŒ–ä¿å­˜è·¯å¾„
}
class Visualizer:
    def __init__(self, cam_K):
        self.K = cam_K

    def draw_cuboid(self, img, rvec, tvec, box_pts_3d, color, thickness=2):
        """ç”»å¹³æ»‘çš„ 3D åŒ…å›´ç›’"""
        # æŠ•å½± 8 ä¸ªè§’ç‚¹
        img_pts, _ = cv2.projectPoints(box_pts_3d[:8], rvec, tvec, self.K, None)
        img_pts = img_pts.squeeze().astype(int)
        
        # 12 æ¡æ£±çš„è¿æ¥å…³ç³»
        edges = [
            (0,1), (0,2), (0,4), (1,3), (1,5), (2,3), 
            (2,6), (3,7), (4,5), (4,6), (5,7), (6,7)
        ]
        
        h, w = img.shape[:2]
        
        # ç»˜åˆ¶
        for s, e in edges:
            # ç®€å•çš„è¾¹ç•Œæ£€æŸ¥ï¼Œé˜²æ­¢ç”»é£å‡ºå±å¹•æŠ¥é”™
            if self._is_in_image(img_pts[s], w, h) or self._is_in_image(img_pts[e], w, h):
                cv2.line(img, tuple(img_pts[s]), tuple(img_pts[e]), color, thickness, cv2.LINE_AA)
        return img

    def draw_axes(self, img, rvec, tvec, length=50):
        """ç”» RGB åæ ‡è½´ (çº¢X, ç»¿Y, è“Z)"""
        center_3d = np.array([[0,0,0]], dtype=np.float32)
        axis_3d = np.array([[length,0,0], [0,length,0], [0,0,length]], dtype=np.float32)
        
        # æŠ•å½±
        center_2d, _ = cv2.projectPoints(center_3d, rvec, tvec, self.K, None)
        axis_2d, _ = cv2.projectPoints(axis_3d, rvec, tvec, self.K, None)
        
        c = tuple(center_2d.squeeze().astype(int))
        axis = axis_2d.squeeze().astype(int)
        
        # BGR é¢œè‰²: Z=çº¢(OpenCVé‡Œé€šå¸¸åç€æ¥ï¼Œè¿™é‡Œæˆ‘ä»¬æŒ‰ RGB=XYZ å¯¹åº” BGR=ZYX)
        # Xè½´ (çº¢)
        cv2.line(img, c, tuple(axis[0]), (0, 0, 255), 3, cv2.LINE_AA)
        # Yè½´ (ç»¿)
        cv2.line(img, c, tuple(axis[1]), (0, 255, 0), 3, cv2.LINE_AA)
        # Zè½´ (è“)
        cv2.line(img, c, tuple(axis[2]), (255, 0, 0), 3, cv2.LINE_AA)
        return img

    def _is_in_image(self, pt, w, h):
        return 0 <= pt[0] < w and 0 <= pt[1] < h

    def create_comparison_image(self, img_path, r_gt, t_gt, r_pred, t_pred, box_pts, error_val):
        """ç”Ÿæˆå¯¹æ¯”å›¾ï¼šå·¦è¾¹ GTï¼Œå³è¾¹ Pred"""
        img_raw = cv2.imread(img_path)
        if img_raw is None: return None
        
        # 1. ç»˜åˆ¶ GT (å·¦å›¾) - è“è‰²æ¡† (255, 0, 0)
        img_gt = img_raw.copy()
        self.draw_cuboid(img_gt, r_gt, t_gt, box_pts, (255, 100, 0), 2) # è“è‰²åæ·±
        cv2.putText(img_gt, "Ground Truth", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
        
        # 2. ç»˜åˆ¶ Pred (å³å›¾) - ç»¿è‰²æ¡† (0, 255, 0) + åæ ‡è½´
        img_pred = img_raw.copy()
        self.draw_cuboid(img_pred, r_pred, t_pred, box_pts, (0, 255, 0), 2)
        # åŠ ä¸Šåæ ‡è½´æ˜¾å¾—æ›´ä¸“ä¸š
        self.draw_axes(img_pred, r_pred, t_pred, length=40)
        
        # å†™ä¸Šè¯¯å·®
        info_text = f"ADD Error: {error_val:.1f} mm"
        color = (0, 255, 0) if error_val < 20 else (0, 0, 255) # è¯¯å·®å°ç»¿å­—ï¼Œå¤§çº¢å­—
        cv2.putText(img_pred, info_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)
        
        # 3. æ‹¼æ¥
        combined = np.hstack([img_gt, img_pred])
        return combined
class BenchmarkRunner:
    def __init__(self):
        self.device = CONFIG["device"]
        os.makedirs(CONFIG["vis_dir"], exist_ok=True)
        
        print(f"Loading Model: {CONFIG['model_path']}")
        self.model = GMGPVNet(num_keypoints=9).to(self.device)
        self.model.load_state_dict(torch.load(CONFIG["model_path"], map_location=self.device))
        self.model.eval()
        
        self.meshes = {} 
        
        # 3D å…³é”®ç‚¹å®šä¹‰ (å¿…é¡»ä¸ DataFactory ä¿æŒä¸€è‡´ï¼Œä¸­å¿ƒç‚¹åœ¨æœ€å)
        s = CONFIG["ref_size"]
        self.box_pts_3d = np.array([
            [s,s,s], [s,s,-s], [s,-s,s], [s,-s,-s],
            [-s,s,s], [-s,s,-s], [-s,-s,s], [-s,-s,-s],
            [0,0,0] # Center at index 8
        ], dtype=np.float32)

    def load_mesh_points(self, obj_id):
        """åŠ è½½ Mesh ç”¨äºè®¡ç®— ADD"""
        if obj_id in self.meshes: return self.meshes[obj_id]
        
        # é™çº§æ–¹æ¡ˆï¼šéšæœºé‡‡æ ·
        s = CONFIG["ref_size"]
        dummy_pts = np.random.uniform(-s, s, (500, 3)).astype(np.float32)
        self.meshes[obj_id] = dummy_pts
        return dummy_pts

    # def get_voting_kpts(self, pred_vec, pred_mask):
    #     """RANSAC / WLS æŠ•ç¥¨"""
    #     c, h, w = pred_vec.shape
    #     mask = torch.sigmoid(pred_mask[0]) > 0.9
    #     y_idxs, x_idxs = torch.where(mask)
        
    #     if len(x_idxs) < 10: return None # åƒç´ å¤ªå°‘ï¼Œè§†ä¸ºæ£€æµ‹å¤±è´¥

    #     coords = torch.stack([x_idxs, y_idxs], dim=1).float().cpu().numpy()
    #     vectors = pred_vec[:, mask].cpu().numpy().T 
        
    #     kpts_pred = []
    #     for k in range(9):
    #         vx = vectors[:, k*2]
    #         vy = vectors[:, k*2+1]
    #         A = np.stack([vy, -vx], axis=1)
    #         b = vy * coords[:, 0] - vx * coords[:, 1]
    #         res, _, _, _ = np.linalg.lstsq(A, b, rcond=None)
    #         kpts_pred.append(res)
            
    #     return np.array(kpts_pred)
    def get_voting_kpts(self, pred_vec, pred_mask):
        """
        RANSAC æŠ•ç¥¨ï¼šæŠ—å™ªèƒ½åŠ›æ›´å¼º
        """
        c, h, w = pred_vec.shape
        # æé«˜ Mask é˜ˆå€¼ï¼Œåªå–æœ€å¯ä¿¡çš„åƒç´ 
        mask = torch.sigmoid(pred_mask[0]) > 0.5
        y_idxs, x_idxs = torch.where(mask)
        
        # ç‚¹å¤ªå°‘ç›´æ¥æ”¾å¼ƒ
        if len(x_idxs) < 30: return None

        coords = torch.stack([x_idxs, y_idxs], dim=1).float().cpu().numpy() # [N, 2]
        vectors = pred_vec[:, mask].cpu().numpy().T # [N, 18]
        
        kpts_2d = []
        
        # å¯¹ 9 ä¸ªå…³é”®ç‚¹åˆ†åˆ«è®¡ç®—
        for k in range(9):
            vx = vectors[:, k*2]
            vy = vectors[:, k*2+1]
            
            # æ„é€  RANSAC éœ€è¦çš„æ•°æ®å½¢å¼
            # è¿™é‡Œçš„æ€è·¯æ˜¯ï¼šæˆ‘ä»¬åœ¨ N ä¸ªåƒç´ ä¸­ï¼Œéšæœºé€‰ 2 ä¸ªç‚¹ï¼Œç®—å‡ºå®ƒä»¬çš„äº¤ç‚¹
            # é‡å¤å¤šæ¬¡ï¼Œçœ‹å“ªä¸ªäº¤ç‚¹è¢«æ”¯æŒå¾—æœ€å¤š
            
            # ä¸ºäº†ç®€å•é«˜æ•ˆï¼Œæˆ‘ä»¬ä½¿ç”¨ OpenCV çš„ RANSAC æ€æƒ³
            # ä½† OpenCV æ²¡æœ‰ç›´æ¥é’ˆå¯¹â€œå‘é‡åœºäº¤ç‚¹â€çš„ RANSAC å‡½æ•°
            # è¿™é‡Œæä¾›ä¸€ä¸ªç®€åŒ–çš„â€œåŠ æƒä¸­ä½æ•°â€ç­–ç•¥ï¼Œæ¯”æœ€å°äºŒä¹˜é²æ£’å¾—å¤š
            
            A = np.stack([vy, -vx], axis=1)
            b = vy * coords[:, 0] - vx * coords[:, 1]
            
            # 1. åˆæ­¥è§£ (æœ€å°äºŒä¹˜)
            initial_kp, _, _, _ = np.linalg.lstsq(A, b, rcond=None)
            
            # 2. è®¡ç®—æ¯ä¸ªåƒç´ å¯¹è¿™ä¸ªè§£çš„â€œæ»¡æ„åº¦â€ (Residual Error)
            # ç†æƒ³å‘é‡ vs å®é™…å‘é‡ çš„ä½™å¼¦ç›¸ä¼¼åº¦
            vec_to_kp = initial_kp - coords
            dist = np.linalg.norm(vec_to_kp, axis=1) + 1e-6
            vec_to_kp_norm = vec_to_kp / dist[:, None]
            
            dot_prod = vec_to_kp_norm[:, 0] * vx + vec_to_kp_norm[:, 1] * vy
            
            # 3. å‰”é™¤ç¦»ç¾¤ç‚¹ (Inlier Selection)
            # åªæœ‰æ–¹å‘åå·®å°äºä¸€å®šè§’åº¦ (æ¯”å¦‚ cos > 0.9) çš„ç‚¹æ‰æ˜¯å¥½ç‚¹
            inliers = dot_prod > 0.9
            
            if np.sum(inliers) > 10:
                # 4. ç”¨å¥½ç‚¹å†ç®—ä¸€æ¬¡ (Refinement)
                A_in = A[inliers]
                b_in = b[inliers]
                final_kp, _, _, _ = np.linalg.lstsq(A_in, b_in, rcond=None)
                kpts_2d.append(final_kp)
            else:
                # å¦‚æœå¥½ç‚¹å¤ªå°‘ï¼Œè¯´æ˜é¢„æµ‹å¾ˆçƒ‚ï¼Œåªèƒ½ç”¨åˆå§‹è§£å‡‘åˆ
                kpts_2d.append(initial_kp)
            
        return np.array(kpts_2d)
    # def compute_add_metric(self, R_pred, t_pred, R_gt, t_gt, obj_id):
    #     pts = self.load_mesh_points(obj_id.item())
    #     pts_pred = (np.dot(pts, R_pred.T) + t_pred.T)
    #     pts_gt = (np.dot(pts, R_gt.T) + t_gt.T)
    #     return np.mean(np.linalg.norm(pts_pred - pts_gt, axis=1))

    def compute_add_metric(self, R_pred, t_pred, R_gt, t_gt, obj_id):
        """
        è®¡ç®—å§¿æ€è¯¯å·®ï¼š
        - éå¯¹ç§°ç‰©ä½“ï¼šä½¿ç”¨ ADD (Average Distance of Model Points)
        - å¯¹ç§°ç‰©ä½“ï¼šä½¿ç”¨ ADD-S (Average Distance of Model Points with Symmetry)
        """
        pts = self.load_mesh_points(obj_id.item())
        
        # 1. å°†æ¨¡å‹ç‚¹äº‘å˜æ¢åˆ°ç›¸æœºåæ ‡ç³»
        pts_pred = (np.dot(pts, R_pred.T) + t_pred.T)
        pts_gt = (np.dot(pts, R_gt.T) + t_gt.T)
        
        # 2. å®šä¹‰å¯¹ç§°ç‰©ä½“çš„ ID åˆ—è¡¨ (YCB-Video æ•°æ®é›†æ ‡å‡†)
        # ID è¯´æ˜: 
        # 13: bowl (ç¢—)
        # 16: abrasive sponge (æµ·ç»µæ“¦ - ä¹Ÿæ˜¯å‡ ä½•å¯¹ç§°çš„)
        # 19: pitcher base (æ°´å£¶åº•)
        # 20: gelatin box (æœå†»ç›’ - çº¹ç†å¯¹ç§°)
        # 21: potted meat (ç½å¤´)
        # 24: extra_large_clamp (å¤§å¤¹å­ - ä¹Ÿæ˜¯å‡ ä½•å¯¹ç§°)
        # è¯·æ ¹æ®ä½ çš„ dataset/test_pbr é‡Œçš„å®é™… obj_id ç¡®è®¤è¿™äº›æ•°å­—
        symmetric_ids = [13, 16, 19, 20, 21, 24,3,9] 
        
        # 3. æ ¹æ®ç‰©ä½“ç±»å‹é€‰æ‹©ç®—æ³•
        if int(obj_id) in symmetric_ids:
            # === ADD-S (é’ˆå¯¹å¯¹ç§°ç‰©ä½“) ===
            # é€»è¾‘ï¼šå¯¹äºé¢„æµ‹ç‚¹äº‘ä¸­çš„æ¯ä¸€ä¸ªç‚¹ï¼Œåœ¨çœŸå€¼ç‚¹äº‘ä¸­æ‰¾ä¸€ä¸ªç¦»å®ƒæœ€è¿‘çš„ç‚¹ç®—è·ç¦»
            # è¿™æ ·å³ä½¿æ—‹è½¬å·®äº† 180 åº¦ï¼ˆå¯¹äºå¯¹ç§°ç‰©ä½“å¤–è§‚ä¸€æ ·ï¼‰ï¼Œè¯¯å·®ä¹Ÿä¼šå¾ˆå°
            kdtree = cKDTree(pts_gt)
            distances, _ = kdtree.query(pts_pred) # è¿”å›æ¯ä¸ªç‚¹çš„æœ€è¿‘é‚»è·ç¦»
            mean_dist = np.mean(distances)
        else:
            # === ADD (é’ˆå¯¹éå¯¹ç§°ç‰©ä½“) ===
            # é€»è¾‘ï¼šç‚¹å¯¹ç‚¹ä¸¥æ ¼å¯¹åº”è®¡ç®—è·ç¦»
            mean_dist = np.mean(np.linalg.norm(pts_pred - pts_gt, axis=1))
            
        return mean_dist

    def draw_visuals(self, img_path, kpts_pred,kpts_gt, rvec, tvec, save_name):
        """ç»˜åˆ¶ 2D å…³é”®ç‚¹å’Œ 3D åŒ…å›´ç›’"""
        img = cv2.imread(img_path)
        if img is None: return

        # 1. ç”» 2D é¢„æµ‹ç‚¹ (é»„è‰²)
        for kp in kpts_pred:
            cv2.circle(img, (int(kp[0]), int(kp[1])), 3, (0, 255, 255), -1)

        # 2. [æ–°å¢] ç”» 2D çœŸå€¼ç‚¹ (çº¢è‰² - GT)
    # è¿™èƒ½è®©ä½ ä¸€çœ¼çœ‹å‡ºæ˜¯ç½‘ç»œé¢„æµ‹æ­ªäº†ï¼Œè¿˜æ˜¯åæ ‡ç³»æœ¬èº«å°±æ­ªäº†
        for kp in kpts_gt:
            cv2.circle(img, (int(kp[0]), int(kp[1])), 2, (0, 0, 255), -1)
            
        # 2. ç”» 3D æŠ•å½±æ¡† (ç»¿è‰²)
        # åªç”¨å‰8ä¸ªè§’ç‚¹ç”»æ¡†
        img_pts, _ = cv2.projectPoints(self.box_pts_3d[:8], rvec, tvec, CONFIG["cam_K"], None)
        img_pts = img_pts.squeeze().astype(int)
        
        # å®šä¹‰ç«‹æ–¹ä½“çš„ 12 æ¡æ£± (åŸºäº 0-7 çš„ç´¢å¼•)
        edges = [
            (0,1), (0,2), (0,4), 
            (1,3), (1,5), 
            (2,3), (2,6), 
            (3,7), 
            (4,5), (4,6), 
            (5,7), 
            (6,7)
        ]
        
        # ç»˜åˆ¶çº¿æ¡†
        for s, e in edges:
            # å¢åŠ è¾¹ç•Œæ£€æŸ¥é˜²æ­¢ç”»å‡ºå›¾å¤–æŠ¥é”™
            if 0 <= s < len(img_pts) and 0 <= e < len(img_pts):
                cv2.line(img, tuple(img_pts[s]), tuple(img_pts[e]), (0, 255, 0), 2)

        cv2.imwrite(save_name, img)

    def run(self):
        dataset = GMGPoseDataset(
            processed_dir=CONFIG["processed_dir"], 
            dataset_root=CONFIG["dataset_root"],
            mode='train' ,
            target_obj_id=CONFIG["target_obj_id"] # <--- ä¼ å…¥è¿™é‡Œ

        )
        
        total_samples = len(dataset)
        if CONFIG["num_eval_samples"]:
            indices = np.random.choice(total_samples, CONFIG["num_eval_samples"], replace=False)
        else:
            indices = range(total_samples)
            
        print(f"Start Benchmarking on {len(indices)} samples...")
        vis_tool = Visualizer(CONFIG["cam_K"])

        # === ç»Ÿè®¡è®¡æ•°å™¨ ===
        stats = {
            "total": len(indices),
            "success_10": 0,    # ADD < 0.1d
            "fail_det": 0,      # Mask åƒç´ ä¸è¶³ (Detection Failed)
            "fail_pnp": 0,      # PnP è§£ç®—å¤±è´¥
            "fail_large_err": 0 # è§£ç®—æˆåŠŸä½†è¯¯å·®è¿‡å¤§
        }
        
        add_errors = []
        diameter = 200.0 # mm
        
        for i, idx in enumerate(tqdm(indices)):
            sample = dataset[idx]
            
            inputs = sample['input'].unsqueeze(0).to(self.device)
            depth = sample['depth'].unsqueeze(0).to(self.device)
            event_points = sample['event_points'].unsqueeze(0).to(self.device) if 'event_points' in sample else None
            if 'template' in sample:
                template = sample['template'].unsqueeze(0).to(self.device)
            else:
                # å®¹é”™ï¼šå¦‚æœæ—§ç‰ˆ Dataset æ²¡è¿”å› templateï¼Œé€ ä¸€ä¸ªå…¨é»‘çš„
                # ä½†è¿™ä¼šä¸¥é‡å½±å“ç²¾åº¦ï¼Œå»ºè®®åŠ¡å¿…æ›´æ–° Dataset
                template = torch.zeros_like(inputs[:, :3, :, :])

            if 'event_points' in sample:
                event_points = sample['event_points'].unsqueeze(0).to(self.device)
            else:
                event_points = None

            # 1. æ¨ç†
            with torch.no_grad():
                # [ä¿®æ”¹] ä¼ å…¥ template
                pred_vec, pred_mask = self.model(inputs, depth, template, event_points)
     
            # 2. æŠ•ç¥¨
            kpts_crop = self.get_voting_kpts(pred_vec[0], pred_mask[0])
            
            # [ç»Ÿè®¡] æ£€æµ‹å¤±è´¥
            if kpts_crop is None:
                stats["fail_det"] += 1
                add_errors.append(1000.0)
                continue
                
            # 3. åæ ‡è¿˜åŸ
            # scale = sample['scale'].numpy()
            # offset = sample['offset'].numpy()
            
            # kpts_global = kpts_crop.copy()
            # kpts_global[:, 0] = kpts_crop[:, 0] / scale[0] + offset[0]
            # kpts_global[:, 1] = kpts_crop[:, 1] / scale[1] + offset[1]

            # # === [æ–°å¢] åæ ‡è¿˜åŸ (GT) ===
            # # ä» Dataset æ‹¿åŸå§‹çš„ local gt
            # kpts_gt_local = sample['kpts_local'].numpy()
            # kpts_gt_global = kpts_gt_local.copy()
            # kpts_gt_global[:, 0] = kpts_gt_local[:, 0] / scale[0] + offset[0]
            # kpts_gt_global[:, 1] = kpts_gt_local[:, 1] / scale[1] + offset[1]
            # # ===========================

            # 3. åæ ‡è¿˜åŸ
            # ç›´æ¥ä¿¡ä»» Dataset ä¼ å‡ºæ¥çš„ scale å’Œ offsetï¼Œå› ä¸ºå®ƒä»¬æ˜¯è®­ç»ƒæ—¶â€œæ¡ˆå‘ç°åœºâ€çš„çœŸå®å‚æ•°
            scale = sample['scale'].numpy()   
            offset = sample['offset'].numpy() 
            
            kpts_global = kpts_crop.copy()
            kpts_global[:, 0] = kpts_crop[:, 0] / scale[0] + offset[0]
            kpts_global[:, 1] = kpts_crop[:, 1] / scale[1] + offset[1]
            
            # åŒç†è¿˜åŸ GT (ç”¨äºç”»çº¢ç‚¹éªŒè¯)
            kpts_gt_local = sample['kpts_local'].numpy()
            kpts_gt_global = kpts_gt_local.copy()
            kpts_gt_global[:, 0] = kpts_gt_local[:, 0] / scale[0] + offset[0]
            kpts_gt_global[:, 1] = kpts_gt_local[:, 1] / scale[1] + offset[1]

            
            # 4. PnP è§£ç®—
            ret_pred, rvec_pred, tvec_pred = cv2.solvePnP(
                self.box_pts_3d, kpts_global, CONFIG["cam_K"], None, flags=cv2.SOLVEPNP_EPNP
            )


            # === [æ–°å¢] è·ç¦»ä¿æŠ¤æœºåˆ¶ ===
            # å¦‚æœç®—å‡ºæ¥çš„è·ç¦»å¤§äº 3ç±³ (YCBåœºæ™¯é€šå¸¸åœ¨1ç±³å·¦å³)ï¼Œè¯´æ˜ç‚¹ç¼©æˆä¸€å›¢äº†
            if tvec_pred[2] > 3000.0: 
                # å¼ºåˆ¶ä¿®æ­£ Z è½´åˆ° 1ç±³ (å‡è®¾)
                # è¿™æ˜¯ä¸€ç§ heuristicï¼Œè™½ç„¶ R è¿˜æ˜¯é”™çš„ï¼Œä½†è‡³å°‘ t ä¸ä¼šç¦»è°±
                scale_factor = 1000.0 / tvec_pred[2]
                tvec_pred = tvec_pred * scale_factor
                # æˆ–è€…æ ‡è®°ä¸ºå¤±è´¥
                # stats["fail_large_err"] += 1
            
            # [ç»Ÿè®¡] PnP å¤±è´¥
            if not ret_pred:
                stats["fail_pnp"] += 1
                add_errors.append(1000.0)
                continue

            ## ç”¨æ·±åº¦å›¾åšæ·±åº¦
            # 1. è·å– crop åŒºåŸŸçš„æ·±åº¦å›¾ (128x128)
            d_crop = depth[0, 0].cpu().numpy() # å•ä½æ˜¯ ç±³
            # 2. è·å–é¢„æµ‹çš„ Mask (åªå–ç½®ä¿¡åº¦é«˜çš„åŒºåŸŸ)
            m_crop = torch.sigmoid(pred_mask[0, 0]).cpu().numpy() > 0.5
            
            if np.sum(m_crop) > 10:
                # å– Mask åŒºåŸŸå†…çš„æ·±åº¦ä¸­ä½æ•°
                valid_depths = d_crop[m_crop]
                # è¿‡æ»¤æ‰ 0 å€¼
                valid_depths = valid_depths[valid_depths > 0]
                
                if len(valid_depths) > 0:
                    z_measured_m = np.median(valid_depths)
                    z_measured_mm = z_measured_m * 1000.0 # æ³¨æ„ï¼šä½ çš„Dataseté‡Œé™¤ä»¥äº†10000ï¼Œè¿™é‡Œè¦ä¹˜å›æ¥
                    
                    # å¼ºè¡Œä¿®æ­£ tvec çš„ Z åˆ†é‡
                    # print(f"Fixing Z: PnP={tvec_pred[2][0]:.1f} -> Depth={z_measured_mm:.1f}")
                    tvec_pred[2] = z_measured_mm
            
            # 5. ç®—åˆ†
            R_pred, _ = cv2.Rodrigues(rvec_pred)
            pose_gt = sample['pose_gt'].numpy()
            R_gt = pose_gt[:3, :3]
            t_gt = pose_gt[:3, 3]

            # è½¬ä¸º rvec ç”¨äº opencv ç”»å›¾
            rvec_gt, _ = cv2.Rodrigues(R_gt)
            tvec_gt = t_gt # shape (3,)
            
            # ç¡®ä¿ tvec_gt æ˜¯ float64 ä¸” shape (3, 1) ä»¥é˜²ä¸‡ä¸€
            tvec_gt = tvec_gt.reshape(3, 1).astype(np.float64)

            # ... (åœ¨ solvePnP ä¹‹å) ...
            
            # === [æ–°å¢] Debug è¯Šæ–­æ¨¡å— (åªæ‰“å°å‰å‡ ä¸ªæ ·æœ¬) ===
            if i < 3: 
                print(f"\n--- Debug Sample {idx} ---")
                print(f"GT Z:   {t_gt[2]:.2f}")
                print(f"Pred Z: {tvec_pred[2][0]:.2f} (Refined)")
                print(f"Error:  {np.linalg.norm(t_gt - tvec_pred.flatten()):.2f}")
                # 1. æ£€æŸ¥ GT å’Œ Pred çš„å¹³ç§»å‘é‡ (t)
                # å¦‚æœ GT æ˜¯ ~1000ï¼ŒPred æ˜¯ ~13000ï¼Œè¯´æ˜ç¡®å®æ˜¯â€œç¼©æˆä¸€å›¢â€å¯¼è‡´æ¨å¾—å¤ªè¿œ
                print(f"GT  tvec (mm): {t_gt.flatten()}")
                print(f"Pred tvec (mm): {tvec_pred.flatten()}")
                
                # 2. æ£€æŸ¥ 2D å…³é”®ç‚¹çš„åˆ†å¸ƒèŒƒå›´ (Spread)
                # è®¡ç®— 2D ç‚¹çš„æ ‡å‡†å·®ï¼Œçœ‹æ˜¯ä¸æ˜¯ç¼©æˆä¸€å›¢
                spread_x = np.std(kpts_global[:, 0])
                spread_y = np.std(kpts_global[:, 1])
                print(f"Pred 2D Spread: X_std={spread_x:.2f}, Y_std={spread_y:.2f}")
                
                # å¦‚æœ std å¾ˆå° (æ¯”å¦‚ < 5.0)ï¼Œè¯´æ˜æ‰€æœ‰ç‚¹éƒ½æŒ¤åœ¨ä¸€èµ· -> æ¨¡å¼åå¡Œ
                if spread_x < 5.0 and spread_y < 5.0:
                    print("âš ï¸ è­¦å‘Šï¼šé¢„æµ‹å…³é”®ç‚¹é‡åˆï¼æ¨¡å‹å‘ç”Ÿäº†æ¨¡å¼åå¡Œ (Mode Collapse)ã€‚")
                else:
                    print("âœ… 2D å…³é”®ç‚¹åˆ†å¸ƒæ­£å¸¸ã€‚")

                # 3. æ£€æŸ¥ 3D æ¡†å°ºå¯¸ (Ref Size)
                # ç¡®ä¿ benchmark é‡Œçš„ ref_size å’Œè®­ç»ƒæ—¶ä¸€è‡´
                print(f"Ref Size used: {CONFIG['ref_size']}")
            # ===============================================

            
            # 6. ç®—åˆ†
            error = self.compute_add_metric(R_pred, tvec_pred.reshape(3), R_gt, t_gt, sample['obj_id'])
            add_errors.append(error)
            
            if error < 0.1 * diameter:
                stats["success_10"] += 1
            else:
                stats["fail_large_err"] += 1

            # 6. å¯è§†åŒ– (æ¯éš” N å¸§ä¿å­˜ä¸€å¼ )
            if i % CONFIG["vis_interval"] == 0:
                save_name = os.path.join(CONFIG["vis_dir"], f"eval_{i}_err{error:.1f}.jpg")
                self.draw_visuals(sample['rgb_path'], kpts_global, kpts_gt_global, rvec_pred, tvec_pred, save_name)
            # [ä¿®æ”¹] å¯è§†åŒ–éƒ¨åˆ†
            if i % CONFIG["vis_interval"] == 0:
                # ä¼ å…¥ GT å’Œ Pred çš„ R, t
                # æ³¨æ„ï¼šrvec éœ€è¦æ˜¯æ—‹è½¬å‘é‡å½¢å¼ï¼Œå¦‚æœä¹‹å‰è½¬æˆäº†çŸ©é˜µ R_predï¼Œè¿™é‡Œè¦è½¬å›æ¥ï¼Œæˆ–è€…ç›´æ¥ç”¨ rvec_pred
                # cv2.Rodrigues å¯ä»¥äº’è½¬
                
                # ç¡®ä¿ box_pts_3d æ˜¯é’ˆå¯¹å½“å‰ç‰©ä½“çš„ (å¦‚æœä½ åšäº†åŠ¨æ€å¤§å°è°ƒæ•´)
                current_box = self.box_pts_3d # æˆ–è€… self.get_box_pts(...)
                
                vis_img = vis_tool.create_comparison_image(
                    sample['rgb_path'],
                    rvec_gt, tvec_gt,       # GT å§¿æ€ (éœ€è¦ä½ ä» pose_gt è½¬ä¸€ä¸‹ rvec)
                    rvec_pred, tvec_pred,   # Pred å§¿æ€
                    current_box,
                    error
                )
                
                if vis_img is not None:
                    save_name = os.path.join(CONFIG["vis_dir"], f"eval_{i}_err_improved{error:.0f}mm.jpg")
                    cv2.imwrite(save_name, vis_img)

        # 7. æ‰“å°æœ€ç»ˆæŠ¥å‘Š
        accuracy = stats["success_10"] / stats["total"] * 100
        mean_error = np.mean(add_errors)
        
        print("\n" + "="*40)
        print(f"Model: {CONFIG['model_path']}")
        print(f"Total Samples: {stats['total']}")
        print("-" * 20)
        print(f"âœ… Accuracy (<10% d): {accuracy:.2f}%")
        print(f"ğŸ“ Mean ADD Error:    {mean_error:.2f} mm")
        print("-" * 20)
        print("Failure Analysis:")
        print(f"âŒ Detection Failed:  {stats['fail_det']} ({stats['fail_det']/stats['total']:.1%}) -> Mask too small/empty")
        print(f"âŒ PnP Failed:        {stats['fail_pnp']} ({stats['fail_pnp']/stats['total']:.1%}) -> Numerical instability")
        print(f"âŒ Large Error:       {stats['fail_large_err']} ({stats['fail_large_err']/stats['total']:.1%}) -> Pose inaccurate")
        print("="*40)
        print(f"Visualizations saved to: {CONFIG['vis_dir']}")

        add_errors = np.array(add_errors)
        
        # ç»Ÿè®¡ä¸åŒé˜ˆå€¼çš„å‡†ç¡®ç‡
        acc_2cm = np.mean(add_errors < 20.0) * 100
        acc_5cm = np.mean(add_errors < 50.0) * 100
        acc_10cm = np.mean(add_errors < 100.0) * 100
        
        # è®¡ç®— AUC (Area Under Curve) - 0åˆ°10cmçš„æ›²çº¿ä¸‹é¢ç§¯
        # è¿™æ˜¯æ›´ç§‘å­¦çš„ç»¼åˆæŒ‡æ ‡
        thresholds = np.linspace(0, 100, 1000) # 0åˆ°10cm
        precision = [(add_errors < t).mean() for t in thresholds]
        auc = np.trapz(precision, thresholds) / 100.0 * 100

        print("\n" + "="*40)
        print(f"Model: {CONFIG['model_path']}")
        print(f"Total Samples: {stats['total']}")
        print("-" * 20)
        print(f"âœ… Acc (< 2 cm):  {acc_2cm:.2f}%  (Strict)")
        print(f"âœ… Acc (< 5 cm):  {acc_5cm:.2f}%  (Coarse)")
        print(f"âœ… Acc (< 10 cm): {acc_10cm:.2f}% (Robust)")
        print(f"ğŸ† AUC (0-10cm):  {auc:.2f}%      (Overall Performance)")
        print("-" * 20)
        print(f"ğŸ“ Mean ADD Error:    {np.mean(add_errors):.2f} mm")
        print(f"ğŸ“ Median ADD Error:  {np.median(add_errors):.2f} mm (æ’é™¤ç¦»ç¾¤ç‚¹)")
        print("="*40)

if __name__ == "__main__":
    bencher = BenchmarkRunner()
    bencher.run()