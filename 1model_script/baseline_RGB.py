import os
import json
import glob
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split
from torchvision import models, transforms
from PIL import Image
from scipy.spatial.transform import Rotation as R
from tqdm import tqdm
import matplotlib.pyplot as plt

# ================= âš™ï¸ é…ç½®åŒºåŸŸ =================
# æŒ‡å‘ dataset æ ¹ç›®å½• (ç¡®ä¿é‡Œé¢æœ‰ 000000/rgb_events)
DATA_ROOT = "../ycb_ev_data/dataset/test_pbr" 

# è¶…å‚æ•°
BATCH_SIZE = 32
LR = 1e-4
EPOCHS = 15            # RGBæ¨¡å‹æ”¶æ•›ç¨æ…¢ï¼Œå»ºè®®å¤šè·‘å‡ è½®
LAMBDA_ROT = 20.0      # æ—‹è½¬Lossçš„æƒé‡ (ç»éªŒå€¼ 10~50)
WEIGHT_DECAY = 1e-4    # é˜²æ­¢è¿‡æ‹Ÿåˆ

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
SAVE_DIR = "./results_rgb"
os.makedirs(SAVE_DIR, exist_ok=True)
# ===============================================

class YCBEventRGBDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.data_list = []

        # æ‰«ææ‰€æœ‰ç‰©ä½“æ–‡ä»¶å¤¹
        obj_dirs = sorted(glob.glob(os.path.join(root_dir, "*")))
        print("æ­£åœ¨æ‰«æ RGB æ•°æ®é›†...")
        
        for obj_dir in obj_dirs:
            if not os.path.isdir(obj_dir): continue
            
            # è¯»å–æ ‡ç­¾
            gt_path = os.path.join(obj_dir, "scene_gt.json")
            if not os.path.exists(gt_path): continue
            
            with open(gt_path, 'r') as f:
                scene_gt = json.load(f)
            
            # è¿™é‡Œçš„æ–‡ä»¶å¤¹åå¿…é¡»æ˜¯ä½ ç”Ÿæˆçš„ "rgb_events"
            img_dir = os.path.join(obj_dir, "rgb_events")
            if not os.path.exists(img_dir): continue
            
            for frame_id_str, gt_data in scene_gt.items():
                img_name = f"{int(frame_id_str):06d}.png"
                img_path = os.path.join(img_dir, img_name)
                
                if os.path.exists(img_path):
                    pose_data = gt_data[0]
                    cam_R = np.array(pose_data['cam_R_m2c']).reshape(3, 3)
                    cam_t = np.array(pose_data['cam_t_m2c'])
                    
                    self.data_list.append({
                        'path': img_path,
                        'R': cam_R,
                        't': cam_t
                    })

        print(f"âœ… åŠ è½½å®Œæˆï¼Œå…± {len(self.data_list)} å¼  RGB å›¾ç‰‡ã€‚")

    def __len__(self):
        return len(self.data_list)

    def __getitem__(self, idx):
        item = self.data_list[idx]
        
        # ã€å…³é”®ã€‘è¯»å–ä¸º RGB (3é€šé“)
        # R=Past, G=Present, B=Future
        image = Image.open(item['path']).convert('RGB')
        
        # --- æ¢é’ˆå¼€å§‹ ---
        img_np = np.array(image)
        # 1. æ£€æŸ¥å›¾ç‰‡æ˜¯å¦å…¨é»‘
        if img_np.max() < 10:
            print(f"ğŸš¨ è­¦å‘Šï¼šå›¾ç‰‡è¿‡æš—æˆ–å…¨é»‘ï¼Max value: {img_np.max()} | Path: {item['path']}")
        
        # 2. æ£€æŸ¥æ ‡ç­¾å•ä½
        t_raw = item['t'] # åŸå§‹æ•°æ®
        if np.max(np.abs(t_raw)) < 1.0:
            # å¦‚æœåŸå§‹æ•°æ®æœ€å¤§å€¼éƒ½ä¸åˆ°1ï¼Œè¯´æ˜æ˜¯ç±³ã€‚ä½ å†é™¤ä»¥1000ï¼Œå°±å˜æˆå¾®ç±³äº†ï¼
            print(f"ğŸš¨ è­¦å‘Šï¼šæ ‡ç­¾æ•°å€¼è¿‡å°ï¼å¯èƒ½å•ä½å·²ç»æ˜¯ç±³äº†ï¼Œä¸è¦é™¤ä»¥1000ï¼Val: {t_raw}")
        # --- æ¢é’ˆç»“æŸ ---


        if self.transform:
            image = self.transform(image)
            
        # å¤„ç†æ ‡ç­¾
        # 1. ä½ç½®å½’ä¸€åŒ–: mm -> m
        t_norm = torch.tensor(item['t'] / 1000.0, dtype=torch.float32)
        
        # 2. æ—‹è½¬çŸ©é˜µ -> å››å…ƒæ•°
        quat = R.from_matrix(item['R']).as_quat() 
        q_norm = torch.tensor(quat, dtype=torch.float32)
        
        # æ‹¼æ¥ [tx, ty, tz, qx, qy, qz, qw]
        label = torch.cat((t_norm, q_norm), dim=0)
        
        return image, label

def get_rgb_model():
    # ä½¿ç”¨ ResNet18
    # weights='DEFAULT' ä¼šè‡ªåŠ¨åŠ è½½ ImageNet é¢„è®­ç»ƒæƒé‡
    # æ ‡å‡† ResNet è¾“å…¥å°±æ˜¯ 3é€šé“ï¼Œæ‰€ä»¥ä¸éœ€è¦æ”¹ç¬¬ä¸€å±‚
    model = models.resnet18(weights='DEFAULT')
    
    # ä¿®æ”¹è¾“å‡ºå±‚ä¸º 7 (3 Pos + 4 Rot)
    num_ftrs = model.fc.in_features
    model.fc = nn.Linear(num_ftrs, 7)
    
    return model

def calculate_metrics(pred, target):
    """è®¡ç®—ç‰©ç†æ„ä¹‰ä¸Šçš„è¯¯å·®: å˜ç±³(cm) å’Œ è§’åº¦(deg)"""
    # pred/target: [B, 7]
    
    # 1. ä½ç½®è¯¯å·® (Euclidean Distance)
    # è¾“å…¥å•ä½æ˜¯ç±³ï¼Œä¹˜ä»¥100å˜å˜ç±³
    pos_pred = pred[:, :3]
    pos_target = target[:, :3]
    pos_error_m = torch.norm(pos_pred - pos_target, dim=1)
    pos_error_cm = pos_error_m * 100.0
    
    # 2. æ—‹è½¬è¯¯å·® (Geodesic Distance)
    # è§’åº¦è¯¯å·® = 2 * arccos( |<q1, q2>| )
    q_pred = pred[:, 3:]
    q_target = target[:, 3:]
    
    # å½’ä¸€åŒ–å››å…ƒæ•° (å¾ˆé‡è¦!)
    q_pred = torch.nn.functional.normalize(q_pred, dim=1)
    q_target = torch.nn.functional.normalize(q_target, dim=1)
    
    # ç‚¹ç§¯
    dot_product = torch.abs(torch.sum(q_pred * q_target, dim=1))
    # é˜²æ­¢æ•°å€¼è¯¯å·®å¯¼è‡´ arccos è¶Šç•Œ
    dot_product = torch.clamp(dot_product, -1.0, 1.0)
    
    angle_error_rad = 2 * torch.acos(dot_product)
    angle_error_deg = torch.rad2deg(angle_error_rad)
    
    return pos_error_cm.mean().item(), angle_error_deg.mean().item()

def plot_history(history):
    """ç”» Loss å’Œ Accuracy æ›²çº¿"""
    epochs = range(1, len(history['train_loss']) + 1)
    
    plt.figure(figsize=(15, 5))
    
    # 1. Loss æ›²çº¿
    plt.subplot(1, 3, 1)
    plt.plot(epochs, history['train_loss'], 'b-', label='Train Loss')
    plt.plot(epochs, history['val_loss'], 'r-', label='Val Loss')
    plt.title('Loss Curve')
    plt.xlabel('Epochs')
    plt.ylabel('Weighted Loss')
    plt.legend()
    plt.grid(True)
    
    # 2. ä½ç½®è¯¯å·®æ›²çº¿
    plt.subplot(1, 3, 2)
    plt.plot(epochs, history['val_pos_err'], 'g-')
    plt.title('Position Error (cm)')
    plt.xlabel('Epochs')
    plt.ylabel('Mean Error (cm)')
    plt.grid(True)

    # 3. æ—‹è½¬è¯¯å·®æ›²çº¿
    plt.subplot(1, 3, 3)
    plt.plot(epochs, history['val_rot_err'], 'm-')
    plt.title('Rotation Error (deg)')
    plt.xlabel('Epochs')
    plt.ylabel('Mean Error (degrees)')
    plt.grid(True)
    
    plt.tight_layout()
    plt.savefig(os.path.join(SAVE_DIR, "training_metrics.png"))
    print(f"ğŸ“Š æ›²çº¿å›¾å·²ä¿å­˜è‡³ {SAVE_DIR}/training_metrics.png")

def main():
    # æ•°æ®å¢å¼º
    transform_train = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ColorJitter(brightness=0.1, contrast=0.1), # è½»å¾®å¢å¼º
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])
    
    transform_val = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])

    full_dataset = YCBEventRGBDataset(DATA_ROOT, transform=None)
    full_dataset.data_list = full_dataset.data_list[:16] # âœ‚ï¸ å¼ºè¡Œåªç•™ 16 ä¸ªæ ·æœ¬
    
    
    # åˆ’åˆ†æ•°æ®é›† (éœ€è¦ç»™ subsets é‡æ–°èµ‹å€¼ transform)
    train_size = int(0.8 * len(full_dataset))
    val_size = len(full_dataset) - train_size
    train_subset, val_subset = random_split(full_dataset, [train_size, val_size])
    
    # æ‰‹åŠ¨è®¾ç½® transform (PyTorch Dataset çš„å° trick)
    # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾ full_dataset.dataset æ˜¯ YCBEventRGBDataset
    # å¦‚æœæŠ¥é”™ï¼Œå¯ä»¥ç›´æ¥åœ¨ Dataset å†…éƒ¨æ ¹æ® phase å¤„ç†ï¼Œè¿™é‡Œç®€åŒ–å¤„ç†ï¼š
    # æˆ‘ä»¬ç›´æ¥è®© Dataset æ¯æ¬¡éƒ½è¿”å› transform åçš„ï¼Œæˆ–è€…è¿™é‡Œç®€å•ç‚¹ï¼š
    # ä¸ºäº†ä¸¥è°¨ï¼Œåº”è¯¥é‡å†™ Dataset æ¥å— splitï¼Œä½†è¿™é‡Œä¸ºäº†ä»£ç çŸ­ï¼Œ
    # æˆ‘ä»¬ç›´æ¥æŠŠ Dataset çš„ transform è®¾ä¸º train çš„ï¼ŒéªŒè¯é›†ä¹Ÿç”¨ä¸€æ ·çš„ï¼ˆåªæ˜¯resize/normï¼‰ï¼Œå½±å“ä¸å¤§
    full_dataset.transform = transform_train
    
    # train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=20)
    # val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=20)

     # è®­ç»ƒ/éªŒè¯é›†éƒ½ç”¨è¿™ 16 ä¸ª
    train_loader = DataLoader(full_dataset, batch_size=4, shuffle=True, num_workers=20) # Batchè®¾å°ç‚¹
    val_loader = DataLoader(full_dataset, batch_size=4, shuffle=False, num_workers=20)

    # æ¨¡å‹
    model = get_rgb_model().to(DEVICE)
    optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)
    
    # å®šä¹‰ä¸¤ä¸ª Loss
    criterion_t = nn.MSELoss()
    criterion_q = nn.L1Loss() # å››å…ƒæ•°ç”¨ L1 å¾€å¾€æ›´å¥½æ”¶æ•›

    # è®°å½•å†å²
    history = {'train_loss': [], 'val_loss': [], 'val_pos_err': [], 'val_rot_err': []}
    best_val_loss = float('inf')

    print(f"ğŸš€ å¼€å§‹è®­ç»ƒ RGB æ¨¡å‹ | Device: {DEVICE}")
    print(f"é…ç½®: Alpha(Rot)={LAMBDA_ROT}, Epochs={EPOCHS}")

    for epoch in range(EPOCHS):
        # --- Training ---
        model.train()
        running_loss = 0.0
        
        pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{EPOCHS}")
        for images, labels in pbar:
            images, labels = images.to(DEVICE), labels.to(DEVICE)
            
            optimizer.zero_grad()
            outputs = model(images)
            
            # æ‹†åˆ† Loss
            loss_t = criterion_t(outputs[:, :3], labels[:, :3])
            loss_q = criterion_q(outputs[:, 3:], labels[:, 3:])
            
            # åŠ æƒæ±‚å’Œ
            loss = loss_t + LAMBDA_ROT * loss_q
            
            loss.backward()
            optimizer.step()
            
            running_loss += loss.item()
            pbar.set_postfix({'Lt': f"{loss_t.item():.4f}", 'Lq': f"{loss_q.item():.4f}"})
            
        epoch_loss = running_loss / len(train_loader)
        
        # --- Validation ---
        model.eval()
        val_loss = 0.0
        pos_errors = []
        rot_errors = []
        
        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(DEVICE), labels.to(DEVICE)
                outputs = model(images)
                
                # Val Loss
                l_t = criterion_t(outputs[:, :3], labels[:, :3])
                l_q = criterion_q(outputs[:, 3:], labels[:, 3:])
                batch_loss = l_t + LAMBDA_ROT * l_q
                val_loss += batch_loss.item()
                
                # ç‰©ç†æŒ‡æ ‡è®¡ç®—
                p_err, r_err = calculate_metrics(outputs, labels)
                pos_errors.append(p_err)
                rot_errors.append(r_err)
        
        avg_val_loss = val_loss / len(val_loader)
        avg_pos_err = sum(pos_errors) / len(pos_errors)
        avg_rot_err = sum(rot_errors) / len(rot_errors)
        
        # è®°å½•
        history['train_loss'].append(epoch_loss)
        history['val_loss'].append(avg_val_loss)
        history['val_pos_err'].append(avg_pos_err)
        history['val_rot_err'].append(avg_rot_err)
        
        print(f"ğŸ“ Epoch {epoch+1} Summary:")
        print(f"   Train Loss: {epoch_loss:.4f} | Val Loss: {avg_val_loss:.4f}")
        print(f"   >>> Err Pos: {avg_pos_err:.2f} cm | Err Rot: {avg_rot_err:.2f} deg")

        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            torch.save(model.state_dict(), os.path.join(SAVE_DIR, "best_rgb_model.pth"))
            print("   ğŸ’¾ New Best Model Saved!")

    # ç»“æŸç”»å›¾
    plot_history(history)
    print("âœ¨ è®­ç»ƒç»“æŸï¼")

if __name__ == "__main__":
    main()