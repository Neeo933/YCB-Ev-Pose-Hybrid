import os
import json
import glob
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split
from torchvision import models, transforms
from PIL import Image
from scipy.spatial.transform import Rotation as R
from tqdm import tqdm
import matplotlib.pyplot as plt

# ================= âš™ï¸ é…ç½®åŒºåŸŸ =================
# æŒ‡å‘ dataset æ ¹ç›®å½• (ç¡®ä¿é‡Œé¢æœ‰ 000000/ev_histogram)
DATA_ROOT = "../ycb_ev_data/dataset/test_pbr" 

# è¶…å‚æ•°
BATCH_SIZE = 32
LR = 1e-4
EPOCHS = 15
LAMBDA_ROT = 20.0      # æ—‹è½¬Lossçš„æƒé‡ (ç»éªŒå€¼ 10~50)
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ç»“æœä¿å­˜è·¯å¾„
SAVE_DIR = "./results_baseline"
os.makedirs(SAVE_DIR, exist_ok=True)
# ===============================================

class YCBEventDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.data_list = []

        # 1. éå†æ‰€æœ‰ç‰©ä½“æ–‡ä»¶å¤¹
        obj_dirs = sorted(glob.glob(os.path.join(root_dir, "*")))
        
        print("æ­£åœ¨æ‰«ææ•°æ®é›† (Baseline)...")
        for obj_dir in obj_dirs:
            if not os.path.isdir(obj_dir): continue
            
            # è¯»å– Ground Truth æ ‡ç­¾
            gt_path = os.path.join(obj_dir, "scene_gt.json")
            if not os.path.exists(gt_path): continue
            
            with open(gt_path, 'r') as f:
                scene_gt = json.load(f)
            
            # éå†è¯¥ç‰©ä½“ä¸‹çš„æ‰€æœ‰å›¾ç‰‡
            for frame_id_str, gt_data in scene_gt.items():
                img_name = f"{int(frame_id_str):06d}.png"
                img_path = os.path.join(obj_dir, "ev_histogram", img_name)
                
                if os.path.exists(img_path):
                    pose_data = gt_data[0] 
                    cam_R = np.array(pose_data['cam_R_m2c']).reshape(3, 3)
                    cam_t = np.array(pose_data['cam_t_m2c'])
                    
                    self.data_list.append({
                        'path': img_path,
                        'R': cam_R,
                        't': cam_t
                    })

        print(f"âœ… æ•°æ®é›†åŠ è½½å®Œæˆï¼Œå…±æ‰¾åˆ° {len(self.data_list)} å¼ å›¾ç‰‡ã€‚")

    def __len__(self):
        return len(self.data_list)

    def __getitem__(self, idx):
        item = self.data_list[idx]
        
        # è¯»å–å›¾ç‰‡ï¼šBaseline é€šå¸¸ä½¿ç”¨å®˜æ–¹çš„ç›´æ–¹å›¾ï¼Œè½¬ä¸º RGB ä»¥é€‚é… ResNet é¢„è®­ç»ƒæƒé‡
        image = Image.open(item['path']).convert('RGB')
        
        if self.transform:
            image = self.transform(image)
            
        # å¤„ç†æ ‡ç­¾
        # å¹³ç§»: mm -> m
        t_norm = torch.tensor(item['t'] / 1000.0, dtype=torch.float32)
        
        # æ—‹è½¬: Matrix -> Quaternion
        quat = R.from_matrix(item['R']).as_quat() 
        q_norm = torch.tensor(quat, dtype=torch.float32)
        
        # æ‹¼æ¥ [tx, ty, tz, qx, qy, qz, qw]
        label = torch.cat((t_norm, q_norm), dim=0)
        
        return image, label

def get_resnet_model():
    # ä½¿ç”¨ ResNet18 é»˜è®¤æƒé‡
    model = models.resnet18(weights='DEFAULT')
    num_ftrs = model.fc.in_features
    model.fc = nn.Linear(num_ftrs, 7)
    return model

def calculate_metrics(pred, target):
    """ã€æ–°å¢ã€‘è®¡ç®—ç‰©ç†æ„ä¹‰ä¸Šçš„è¯¯å·®: å˜ç±³(cm) å’Œ è§’åº¦(deg)"""
    # pred/target: [B, 7]
    
    # 1. ä½ç½®è¯¯å·® (Euclidean Distance)
    # è¾“å…¥å•ä½æ˜¯ç±³ï¼Œä¹˜ä»¥100å˜å˜ç±³
    pos_pred = pred[:, :3]
    pos_target = target[:, :3]
    pos_error_m = torch.norm(pos_pred - pos_target, dim=1)
    pos_error_cm = pos_error_m * 100.0
    
    # 2. æ—‹è½¬è¯¯å·® (Geodesic Distance)
    # è§’åº¦è¯¯å·® = 2 * arccos( |<q1, q2>| )
    q_pred = pred[:, 3:]
    q_target = target[:, 3:]
    
    # å½’ä¸€åŒ–å››å…ƒæ•° (å¾ˆé‡è¦! ç½‘ç»œè¾“å‡ºçš„å››å…ƒæ•°æ¨¡é•¿ä¸ä¸€å®šæ˜¯1)
    q_pred = torch.nn.functional.normalize(q_pred, dim=1)
    q_target = torch.nn.functional.normalize(q_target, dim=1)
    
    # ç‚¹ç§¯
    dot_product = torch.abs(torch.sum(q_pred * q_target, dim=1))
    # é˜²æ­¢æ•°å€¼è¯¯å·®å¯¼è‡´ arccos è¶Šç•Œ
    dot_product = torch.clamp(dot_product, -1.0, 1.0)
    
    angle_error_rad = 2 * torch.acos(dot_product)
    angle_error_deg = torch.rad2deg(angle_error_rad)
    
    return pos_error_cm.mean().item(), angle_error_deg.mean().item()

def plot_history(history):
    """ã€æ–°å¢ã€‘ç”» Loss å’Œ Error æ›²çº¿"""
    epochs = range(1, len(history['train_loss']) + 1)
    
    plt.figure(figsize=(15, 5))
    
    # 1. Loss æ›²çº¿
    plt.subplot(1, 3, 1)
    plt.plot(epochs, history['train_loss'], 'b-', label='Train Loss')
    plt.plot(epochs, history['val_loss'], 'r-', label='Val Loss')
    plt.title('Loss Curve')
    plt.xlabel('Epochs')
    plt.ylabel('MSE Loss')
    plt.legend()
    plt.grid(True)
    
    # 2. ä½ç½®è¯¯å·®æ›²çº¿
    plt.subplot(1, 3, 2)
    plt.plot(epochs, history['val_pos_err'], 'g-')
    plt.title('Position Error (cm)')
    plt.xlabel('Epochs')
    plt.ylabel('Mean Error (cm)')
    plt.grid(True)

    # 3. æ—‹è½¬è¯¯å·®æ›²çº¿
    plt.subplot(1, 3, 3)
    plt.plot(epochs, history['val_rot_err'], 'm-')
    plt.title('Rotation Error (deg)')
    plt.xlabel('Epochs')
    plt.ylabel('Mean Error (degrees)')
    plt.grid(True)
    
    plt.tight_layout()
    plt.savefig(os.path.join(SAVE_DIR, "baseline_metrics.png"))
    print(f"ğŸ“Š æ›²çº¿å›¾å·²ä¿å­˜è‡³ {SAVE_DIR}/baseline_metrics.png")

def main():
    # æ•°æ®é¢„å¤„ç†
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])

    full_dataset = YCBEventDataset(DATA_ROOT, transform=transform)
    
    if len(full_dataset) == 0:
        print("é”™è¯¯ï¼šæœªæ‰¾åˆ°æ•°æ®ï¼")
        return

    # åˆ’åˆ†æ•°æ®é›†
    train_size = int(0.8 * len(full_dataset))
    val_size = len(full_dataset) - train_size
    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])

    # æ³¨æ„ï¼šå¦‚æœ num_workers=20 æŠ¥é”™ï¼Œè¯·æ”¹ä¸º 4 æˆ– 0
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=20)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=20)

    model = get_resnet_model().to(DEVICE)
    optimizer = optim.Adam(model.parameters(), lr=LR)
    # criterion = nn.MSELoss()
     # å®šä¹‰ä¸¤ä¸ª Loss
    criterion_t = nn.MSELoss()
    criterion_q = nn.L1Loss() # å››å…ƒæ•°ç”¨ L1 å¾€å¾€æ›´å¥½æ”¶æ•›

    # è®°å½•å†å²
    history = {'train_loss': [], 'val_loss': [], 'val_pos_err': [], 'val_rot_err': []}
    best_val_loss = float('inf')

    print(f"ğŸš€ å¼€å§‹è®­ç»ƒ Baseline æ¨¡å‹ | Device: {DEVICE}")

    for epoch in range(EPOCHS):
        # --- Training ---
        model.train()
        running_loss = 0.0
        
        pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{EPOCHS}")
        for images, labels in pbar:
            images, labels = images.to(DEVICE), labels.to(DEVICE)
            
            optimizer.zero_grad()
            outputs = model(images)
            # loss = criterion(outputs, labels)

            # æ‹†åˆ† Loss
            loss_t = criterion_t(outputs[:, :3], labels[:, :3])
            loss_q = criterion_q(outputs[:, 3:], labels[:, 3:])
            
            # åŠ æƒæ±‚å’Œ
            loss = loss_t + LAMBDA_ROT * loss_q

            loss.backward()
            optimizer.step()
            
            running_loss += loss.item()
            pbar.set_postfix({'Loss': loss.item()})
            
        epoch_loss = running_loss / len(train_loader)
        
        # --- Validation ---
        model.eval()
        val_loss = 0.0
        pos_errors = []
        rot_errors = []
        
        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(DEVICE), labels.to(DEVICE)
                outputs = model(images)
                
                # Val Loss
                l_t = criterion_t(outputs[:, :3], labels[:, :3])
                l_q = criterion_q(outputs[:, 3:], labels[:, 3:])
                batch_loss = l_t + LAMBDA_ROT * l_q
                val_loss += batch_loss.item()
                
                # è®¡ç®—ç‰©ç†è¯¯å·®
                p_err, r_err = calculate_metrics(outputs, labels)
                pos_errors.append(p_err)
                rot_errors.append(r_err)
        
        avg_val_loss = val_loss / len(val_loader)
        avg_pos_err = sum(pos_errors) / len(pos_errors)
        avg_rot_err = sum(rot_errors) / len(rot_errors)
        
        # è®°å½•å†å²
        history['train_loss'].append(epoch_loss)
        history['val_loss'].append(avg_val_loss)
        history['val_pos_err'].append(avg_pos_err)
        history['val_rot_err'].append(avg_rot_err)
        
        # æ‰“å°è¯¦ç»†æ—¥å¿—
        print(f"ğŸ“ Epoch {epoch+1} Summary:")
        print(f"   Train Loss: {epoch_loss:.4f} | Val Loss: {avg_val_loss:.4f}")
        print(f"   >>> Err Pos: {avg_pos_err:.2f} cm | Err Rot: {avg_rot_err:.2f} deg")

        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            torch.save(model.state_dict(), os.path.join(SAVE_DIR, "baseline_model.pth"))
            # print("   ğŸ’¾ Best Model Saved!")

    # è®­ç»ƒç»“æŸï¼Œç”»å›¾
    plot_history(history)
    print(f"âœ¨ è®­ç»ƒç»“æŸï¼ç»“æœå·²ä¿å­˜è‡³ {SAVE_DIR}")

if __name__ == "__main__":
    main()